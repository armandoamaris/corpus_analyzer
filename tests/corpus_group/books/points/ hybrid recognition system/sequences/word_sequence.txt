katiyar
and
mehfuz
springerplus
2016)5:357
sprl
ge
pi
us
doi
10.1186/540064-016-1775-7
open
access
hybrid
recognition
system
for
off-line
handwritten
characters
gauri
katiyar
and
shabana
mehfuz
correspondence
gaurikatiyar0208@yahoo
com
gaurikatiyarrl@its.edu.in
department
of
electrical
engineering
jamia
millia
islamia
new
delhi
india
full
list
of
author
information
is
available
at
the
end
of
the
article
springer
open
abstract
computer
based
pattern
recognition
is
process
that
involves
several
sub-processes
including
pre-processing
feature
extraction
feature
selection
and
classification
fea
ture
extraction
is
the
estimation
of
certain
attributes
of
the
target
patterns
selection
of
the
right
set
of
features
is
the
most
crucial
and
complex
part
of
building
pattern
recognition
system
in
this
work
we
have
combined
multiple
features
extracted
using
seven
different
approaches
the
novelty
of
this
approach
is
to
achieve
better
accuracy
and
reduced
computational
time
for
recognition
of
handwritten
characters
using
genetic
algorithm
which
optimizes
the
number
of
features
along
with
simple
and
adaptive
multi
layer
perceptron
classifier
experiments
have
been
performed
using
standard
database
of
cedar
centre
of
excellence
for
document
analysis
and
recogni
tion
for
english
alphabet
the
experimental
results
obtained
on
this
database
demon
strate
the
effectiveness
of
this
system
keywords
character
recognition
multi
layer
perceptron
feature
extraction
genetic
algorithm
background
machine
simulation
of
functional
perspective
of
human
being
has
been
significant
and
vital
research
area
in
the
field
of
image
processing
and
pattern
recognition
plamon
don
and
srihari
2000
arica
and
yarman-vural
2001
handwriting
recognition
is
the
mechanism
for
converting
the
handwritten
text
into
notational
representation
it
is
special
problem
in
the
domain
of
pattern
recognition
and
machine
intelligence
char
acter
recognition
can
be
split
up
into
two
modes
online
and
offline—depending
on
the
type
of
available
data
online
character
recognition
involves
the
identification
of
char
acter
while
they
are
being
written
and
are
captured
by
special
hardware
e.g
smart
pen
or
pressure
sensitive
tablets
which
is
capable
of
measuring
pen’s
pressure
and
velocity
offline
character
recognition
on
the
other
hand
are
written
on
paper
with
ordinary
pens
and
converted
into
scanned
digital
images
systems
for
recognizing
machine
printed
text
originated
in
the
late
1950s
and
have
been
in
widespread
use
on
desktop
computers
since
the
early
1990s
in
the
early
1990s
image
processing
and
pattern
recognition
are
efficiently
and
effectively
combined
with
artificial
intelligence
and
statistical
technique
that
is
hidden
morkov
model
hmm
avi-itzhak
et
al
1995
chen
et
al
1994
2016
katiyar
and
mehfuz
this
article
is
distributed
under
the
terms
of
the
creative
commons
attribution
4.0
international
license
http//creativecommons.org/licenses/by/4.0/
which
permits
unrestricted
use
distribution
and
reproduction
in
any
medium
pro
vided
you
give
appropriate
credit
to
the
original
author(s
and
the
source
provide
link
to
the
creative
commons
license
and
indicate
if
changes
were
made
katiyar
and
mehfuz
springerplus
2016)5:357
page
0f
18
off-line
handwritten
character
recognition
continues
to
be
an
active
research
area
towards
exploring
the
newer
techniques
because
it
has
various
applications
such
as
postal
sorting
bank
cheque
amount
reading
and
official
document
reading
mori
et
al
1992
presented
historical
review
of
off-line
character
recognition
research
and
development
comprehensive
survey
of
recognition
techniques
has
been
reported
in
govindan
and
shivaprasad
1990
mehfuz
and
katiyar
2012
katiyar
and
mehfuz
2012
survey
on
on-line
and
off-line
handwritten
and
hand
printed
character
recognition
has
already
been
presented
plamondon
and
srihari
2000
recognition
of
cursive
hand
written
character
is
difficult
task
most
of
the
researchers
have
conducted
their
work
on
unconstrained
character
hanmandlu
et
al
2003
saurabh
and
singh
2011
lee
1996
feature
selection
is
process
of
selecting
only
significant
features
from
large
data
base
to
create
subset
of
the
original
database
this
process
retains
the
original
feature
without
changing
the
features
domain
the
main
objectives
of
the
feature
selection
are
to
reduce
database
dimensionally
remove
irrelevant
features
reduce
time
needed
to
learn
the
classification
function
increase
accuracy
and
to
keep
only
important
features
that
give
comprehensive
understandings
for
all
variables
demand
of
feature
selection
is
currently
rising
because
of
the
expanding
sizes
of
databases
in
various
applications
there
are
many
ways
of
feature
selection
using
search
algorithms
such
as
sequential
forward
selection
ses
sequential
backward
selection
sbs
exhaustive
search
and
genetic
algorithm
ga
exhaustive
search
is
not
suitable
for
large
database
as
it
is
time
consuming
process
sfs
and
sbs
operations
are
good
because
all
features
in
data
base
are
evaluated
at
the
same
time
however
once
feature
is
removed
it
does
not
have
chance
of
being
selected
again
the
selected
features
will
remain
in
the
selection
even
after
new
features
selected
resulting
some
redundancies
in
some
cases
ga
differs
from
this
type
of
feature
selection
method
due
to
the
capability
to
evolve
new
features
from
the
selected
features
and
vast
exploration
of
search
space
for
new
fitter
solutions
the
evolving
process
is
made
possible
using
ga
operators
which
are
selection
cross-over
and
mutations
the
process
will
continue
until
the
best
solutions
are
found
or
the
maxi
mum
number
of
iterations
is
met
de
stefano
et
al
2002
have
investigated
the
possibility
of
using
pre-classification
technique
for
reducing
the
number
of
classes
they
have
used
genetic
programming
for
pre
classification
parkins
and
nandi
2004
have
used
genetic
algorithm
based
feature
selection
and
neural
network
as
classifier
for
handwritten
digit
recognition
in
sau
rabh
and
singh
2011
performance
of
feed-forward
neural
networks
for
recognition
of
handwritten
english
alphabet
has
been
evaluated
with
three
different
soft
computing
techniques
namely
back-propagation
evolutionary
algorithm
and
hybrid
evolutionary
algorithm
the
authors
have
presented
ga
based
feature
selection
algorithm
for
detecting
fea
ture
subsets
where
the
samples
belonging
to
different
classes
are
properly
classified
de
stefano
et
al
2013
das
et
al
2012
have
applied
ga
to
extract
the
optimal
fea
ture
set
that
has
the
best
discriminating
features
to
recognise
the
handwritten
bangla
digits
to
recognise
handwritten
farsi/arabic
digit
mlpnn
multilayer
perceptron
neural
network
with
back-propagation
as
classifier
has
been
used
shayegan
and
chan
2012
by
employing
and
2d
spectrum
diagram
for
standard
deviation
and
minimum
katiyar
and
mehfuz
springerplus
2016)5:357
page
0f
18
to
maximum
distribution
an
optimal
subset
of
initial
feature
subset
was
selected
automatically
the
authors
have
proposed
fast
and
efficient
solution
based
on
genetic
algorithm
to
solve
the
feature
selection
problems
chouaib
et
al
2012
lanzi
1997
lp-norms
gener
alized
principle
component
analysis
pca
for
dimensionality
reduction
has
been
pro
posed
in
liang
et
al
2013
to
recognise
chinese
character
genetic
algorithm
based
feature
selection
method
with
support
vector
machine
as
classifier
has
been
proposed
feng
et
al
2004
multi
objective
genetic
algorithm
has
been
used
for
feature
selection
for
handwriting
recognition
oliveira
et
al
2002
the
authors
have
proposed
new
feature
selection
method
for
multi
class
problem
based
on
recursive
feature
elimination
in
least
square
support
vector
machine
ls-svm
zeng
and
chen
2009
in
another
work
the
authors
have
proposed
simple
multilayer
cluster
neutral
network
with
five
independent
sub
networks
for
off-line
recognition
of
totally
unconstrained
handwritten
numeral
and
genetic
algorithm
have
been
used
to
avoid
problems
of
finding
local
minima
in
training
the
multilayer
cluster
neural
network
with
gradient
descent
techniques
lee
and
kim
1994
lee
1995
1996
comparison
of
five
feature
selection
methods
using
neural
net
work
as
classifier
for
handwritten
character
recognition
has
been
presented
in
chung
and
yoon
1997
in
cho
1999
ga
determines
the
optimal
weight
parameter
of
the
neural
network
to
classify
the
unconstrained
handwritten
numerals
in
our
work
ga
has
been
used
for
feature
selection
because
of
its
potential
as
an
optimization
technique
for
complex
problems
advantage
of
this
approach
include
the
ability
to
accommodate
multiple
criteria
such
as
number
of
features
and
accuracy
of
classifier
as
well
as
the
capacity
to
deal
with
huge
database
in
order
to
adequately
repre
sent
the
pattern
recognition
problem
the
decision
making
part
of
the
recognition
system
is
the
classification
stage
the
efficiency
of
the
classifier
depends
on
the
quality
of
the
features
different
classification
techniques
for
character
recognition
can
be
split
up
into
two
general
approaches
pla
mondon
and
srihari
2000
arica
and
yarman-vural
2001
classical
techniques
template
matching
statistical
techniques
and
structural
techniques
soft
computing
techniques
artificial
neural
networks
anns
fuzzy
logic
technique
and
evolutionary
computing
techniques
nowadays
classical
techniques
are
not
extensively
used
in
this
area
of
research
because
the
performance
of
classical
techniques
are
dependent
on
the
amount
of
data
used
in
the
defining
the
parameters
of
statistical
model
and
are
not
flexible
enough
to
adapt
to
new
handwriting
constraints
moreover
these
techniques
can
be
used
only
when
the
input
data
is
uniform
with
respect
to
time
recognition
techniques
based
on
neural
network
has
been
currently
taking
more
attention
of
researchers
quick
recogni
tion
automatic
learning
and
flexibility
once
the
networks
are
properly
trained
are
some
of
the
advantages
of
ann
therefore
we
have
chosen
neural
network
as
classifier
in
our
recognition
system
katiyar
and
mehfuz
springerplus
2016)5:357
page
0f
18
contribution
of
this
work
to
improve
the
performance
of
the
off-line
handwritten
character
recognition
system
either
the
performance
of
the
classifier
has
to
be
improved
or
better
feature
extraction
techniques
and/or
feature
selection
techniques
need
to
be
explored
we
have
presented
methodology
for
hybrid
feature
extraction
and
genetic
algorithm
based
approach
for
optimal
selection
of
feature
subset
along
with
an
adaptive
multi
layer
perception
mlp
as
pattern
classifier
adaptive
nature
in
the
classifier
is
achieved
by
implement
ing
function
for
selection
of
best
architecture
of
mlp
during
the
feature
selection
and
classification
phases
we
have
extracted
seven
feature
sets
based
on
moment
features
distance-based
feature
geometrical
feature
and
local
features
as
discussed
in
the
follow
ing
section
the
effectiveness
of
the
method
is
tested
on
the
problem
of
off-line
hand
written
character
recognition
to
address
the
problem
of
diversity
in
style
size
and
shape
which
can
be
found
in
handwriting
produced
by
different
writers
all
the
handwritten
data
considered
here
are
unconstrained
alphabets
to
avoid
the
process
of
segmentation
selection
of
features
also
plays
an
important
role
in
improving
the
performance
of
the
system
the
novelty
of
the
proposed
recognition
system
is
that
by
hybridization
of
the
feature
extraction
techniques
and
randomly
selecting
the
features
using
ga
along
with
an
adaptive
mlp
neural
network
classifier
the
accuracy
of
the
system
is
improved
and
the
computational
time
of
the
system
is
reduced
proposed
recognition
system
the
objective
of
the
proposed
work
is
to
use
ga
based
feature
reduction
technique
to
develop
an
off-line
character
recognition
system
using
adaptive
neural
network
as
classifier
the
following
steps
have
been
adopted
in
the
algorithm
for
character
recognition
input
pre-processing
feature
extraction
feature
selection
using
ga
«»
artificial
neural
network
based
classifier
all
the
above
mentioned
stages
and
their
interconnection
for
the
proposed
recogni
tion
system
are
shown
in
fig
1
input
database
for
off-line
handwritten
english
alphabets
recognition
the
benchmark
dataset
used
by
researchers
is
cedar
center
for
excellence
in
document
analysis
and
recognition
usa
cdrom-1
the
database
has
been
acquired
from
cedar
buffalo
university
usa
http://www.cedar.buffalo.edu/ilt/research.html
the
bi-tonal
images
of
alphabetic
and
numeric
characters
in
the
database
are
divided
into
two
groups
one
group
contains
mixed
alphabetic
and
numeric
binanums
and
the
other
group
contains
numeric
characters
bindigis
only
the
separation
of
database
into
training
and
testing
set
is
katiyar
and
mehfuz
springerplus
2016)5:357
page
50f
18
input
image
feature
extraction
feature
selection
using
ga
adaptive
neural
fig
block
diagram
of
the
proposed
recognition
system
shown
in
table
hull
1995
there
are
19,145
known
alphabet
characters
in
training
set
and
2183
unknown
alphabet
characters
in
testing
set
preprocessing
the
main
goal
of
the
pre-processing
is
to
arrange
the
information
to
make
the
character
recognition
process
simpler
the
following
pre-processing
steps
have
been
applied
binarization
in
order
to
avoid
the
problems
resulting
due
to
noise
and
lost
information
the
gray
scale
image
of
up
to
256
gray
levels
is
converted
into
binary
matrix
we
have
used
global
thresholding
method
for
binarization
if
the
intensity
of
the
pixel
is
more
than
par
ticular
threshold
value
it
is
set
to
white
represented
by
1
and
otherwise
to
black
rep
resented
by
0
in
this
work
we
have
chosen
mean
mean
image
as
threshold
the
threshold
value
changes
as
the
images
change
slant
correction
slant
is
defined
as
slope
of
the
general
writing
trend
with
respect
to
the
vertical
line
the
image
matrix
is
divided
into
upper
and
lower
halves
the
centers
of
gravity
of
the
lower
and
upper
halves
are
computed
and
connected
the
slope
of
the
connecting
line
defines
the
slope
of
the
window
image
matrix
hanmandlu
et
al
2003
hanmandlu
and
mur
thy
2007
katiyar
and
mehfuz
springerplus
2016)5:357
page
of
18
table
number
of
samples
from
cedar
cdrom-1for
training
and
testing
capital
alphabet
training
set
testing
set
small
alphabet
training
set
testing
set
1237
162
57
68
595
69
84
588
51
21
17
388
49
249
26
490
57
736
107
287
32
120
16
143
19
93
14
247
25
205
23
490
56
803
70
68
15
160
19
94
14
563
87
684
69
588
59
184
21
1022
123
469
60
905
102
833
84
516
59
129
749
97
460
47
834
77
490
29
441
54
428
46
268
31
333
26
201
27
127
20
249
30
102
15
112
19
173
10
259
39
136
15
24
15
total
11,454
1367
total
7691
816
smoothing
and
noise
removal
exact
surrounding
region
of
character
image
can
be
determined
by
smoothing
using
wiener
filter
median
filter
is
applied
to
further
enhance
the
image
quality
by
removing
any
leftover
noise
normalization
normalization
is
required
as
the
size
of
the
character
varies
from
one
person
to
another
and
also
from
time
to
time
even
when
the
person
is
same
normalization
helps
in
equat
ing
the
size
of
the
character
image
binary
matrix
so
that
features
can
be
extracted
on
the
same
footing
the
character
image
is
standardized
to
window
size
of
42
32
as
shown
in
fig
2
feature
extraction
and
feature
selection
for
any
recognition
system
feature
extraction
is
an
integral
part
there
are
several
fea
ture
extraction
techniques
and
its
selection
is
the
most
crucial
factor
in
achieving
high
accuracy
the
right
choice
of
the
features
from
the
whole
available
set
is
the
most
impor
tant
step
in
any
classification
process
different
feature
selection
approaches
have
been
proposed
in
literature
trier
et
al
1996
katiyar
and
mehfuz
springerplus
2016)5:357
42
+—>
32
fig
normalisation
of
an
image
into
window
size
of
42
32
feature
extraction
at
this
stage
the
features
of
the
characters
that
are
crucial
for
classifying
them
at
recog
nition
stage
are
extracted
we
have
extracted
seven
sets
of
feature
vectors
the
methods
of
feature
extraction
are
as
follows
box
approach
box
approach
is
based
on
spatial
division
of
character
image
horizontal
and
vertical
grid
lines
of
are
superimposed
on
the
character
image
of
size
42
32
in
this
process
24
boxes
each
of
size
are
devised
some
of
the
boxes
will
have
por
tion
of
the
image
and
others
remain
empty
however
all
boxes
are
considered
for
analysis
hanmandlu
et
al
2003
hanmandlu
and
murthy
2007
as
shown
in
fig
3
normalized
vector
distance
for
each
box
is
computed
as
1
vb:n—bzdk
k=1
df
=@+
where
ny
is
number
of
pixels
in
bth
box
217
4
12
17
70
nnnnnrnr
nnnanrn
nnnnnnn
nnnrrrn
nanrarrn
dannnnnn
32
fig
diagonal
distance
feature
extraction
method
page
of
18
katiyar
and
mehfuz
springerplus
2016)5:357
page
of
18
normalized
angle
for
each
box
is
computed
as
ay=
o
whereb
=1
2,...,24
6
tan’l(—j/i
for
pixel
at
i
j
these
24
pairs
constitute
the
feature
set
diagonal
distance
approach
every
character
image
of
size
42
32
pixels
is
divided
into
24
equal
zones
each
of
size
pixels
the
features
are
extracted
from
each
zone
pix
els
by
moving
along
the
diagonals
of
its
respective
pixels
each
zone
has
14
diagonal
lines
thus
14
sub-features
are
obtained
from
the
each
zone
these
14
sub-features
values
are
averaged
to
form
single
feature
value
and
placed
in
the
corresponding
zone
finally
24
features
are
extracted
for
each
character
pradeep
et
al
2011
the
complete
process
is
shown
in
fig
3
mean
mean
gives
an
idea
of
what
pixels
color
to
choose
to
assess
the
color
of
the
com
plete
image
it
is
measured
by
taking
sum
of
all
the
pixels
and
dividing
them
by
total
number
of
pixels
of
each
box
thus
24
features
of
each
image
are
obtained
the
mean
for
each
box
is
commutated
as
xi
i=1
m=
mean
=x
where
total
number
of
pixels
in
each
box
gradient
operations
image
gradient
is
the
variations
of
pixels
in
horizontal
and
verti
cal
directions
image
gradient
may
be
used
to
extract
information
from
images
the
gra
dients
have
been
calculated
by
using
the
following
formula
vf
vf
gradient
vf
i+
j
radien
th+
vy
5
af]ax
gradient
in
the
x-direction
for
pixel
at
i
j
af/ay
gradient
in
the
y-direc
tion
for
pixel
at
i
j
gradient
have
been
measured
for
each
box
this
process
is
sequentially
repeated
for
all
the
24
boxes
thus
48
features
are
extracted
from
24
boxes
standard
deviation
standard
deviation
sd
of
pixels
in
each
box
has
been
calculated
this
process
is
applied
for
all
24
boxes
to
obtain
24
features
sd:g:"nz
x
x)2
6
where
is
number
of
rows
and
is
mean
katiyar
and
mehfuz
springerplus
2016)5:357
page
of
18
center
of
gravity
cg
centre
of
gravity
of
the
pixels
in
each
box
is
obtained
in
this
process
we
get
total
48
features
for
all
the
24
boxes
bg
bj
yo
cg
x
where
b(i
j
is
binary
region
and
is
given
as
b(i,j
1if
i,j
in
region
or
otherwise
area
edge
detection
edge
detection
is
performed
on
each
box
and
finds
the
sum
of
values
at
edge
pixel
positions
sobel
edge
detection
function
has
been
used
for
this
step
the
magnitude
of
the
gradient
of
the
image
is
calculated
for
each
pixel
position
in
the
image
according
to
the
following
formula
mag(vf
fx
f
®
where
f
gradient
in
direction
f
gradient
in
direction
this
process
is
applied
for
all
24
boxes
to
get
24
features
thus
with
the
help
of
all
the
seven
feature
extraction
methods
we
obtain
240
number
of
features
for
each
image
matrix
hybrid
features
we
have
obtained
set
of
240
features
from
seven
different
approaches
instead
of
using
single
approach
we
have
combined
all
features
obtained
by
different
methods
this
combination
forms
hybrid
feature
set
and
is
stored
in
feature
vector
this
vector
contains
total
of
240
features
set
and
is
used
for
recognizing
the
character
table
specifies
the
number
of
features
extracted
by
using
various
feature
extraction
techniques
feature
selection
in
this
work
ga
has
been
used
for
feature
selection
figure
shows
the
basic
steps
of
feature
selection
subsystem.ga
is
implemented
on
hybrid
features
to
create
subset
of
best
features
feature
selection
can
be
classified
into
two
main
approaches
filter
and
wrapper
approaches
in
filter
approach
evaluation
is
normally
done
independently
of
any
classifier
we
have
used
wrapper
approach
for
implementing
ga
to
evaluate
feature
subset
wrapper
approach
employs
classifier’s
predictive
accuracy
for
the
evaluation
of
table
features
description
feature
set
number
of
features
box
features
48
diagonal
distance
24
mean
24
gradient
operations
48
standard
deviation
24
centre
of
gravity
48
edge
detection
24
total
240
katiyar
and
mehfuz
springerplus
2016)5:357
page
10
of
18
images
feature
extraction
feature
selection
using
ga
best
features
yes
train
the
classifier
fig
flow
chart
for
feature
extraction
and
feature
selection
sub
system
the
subset
of
features
the
classifier
used
here
is
ann
which
imparts
hybrid
nature
to
the
feature
selection
process
procedure
to
prune
the
feature
set
dimensionally
for
initial
population
we
have
cho
sen
four
chromosomes
where
size
of
each
chromosome
is
equal
to
the
dimensionality
of
the
feature
set
which
is
equal
to
240
as
we
have
extracted
240
features
set
in
the
feature
extraction
step
in
chromosome
represents
presence
of
that
particular
dimension
and
represents
absence
of
the
same
see
fig
5
bit
string
encoding
of
each
chromosome
has
been
shown
in
fig
6
for
each
chromosome
we
have
formed
the
relevant
feature
set
say
f1
f2
f3
and
f4
see
table
3
by
using
these
relevant
feature
set
we
performed
training
of
neural
network
and
cal
culated
the
accuracy
which
has
been
considered
as
the
fitness
function
of
that
particular
chromosome
then
we
have
calculated
the
average
of
fitness
values
of
all
the
chromo
somes
this
process
continues
until
convergence
to
get
the
new
sets
of
chromosomes
the
fittest
chromosomes
undergo
reproduction
cross
over
and
mutation
process
again
for
each
new
chromosome
we
form
relevant
feature
set
and
train
the
neural
network
and
calculate
the
accuracy
using
eq
9
which
is
the
fitness
function
the
average
of
all
<4—————————————features
mmmmm
f2
f3
fa
faze
faa0
efo
10
fig
initial
populations
katiyar
and
mehfuz
springerplus
2016)5:357
page
11
of
18
ff
fae
a0
240
bits
notconsidered
+
+
considered
fig
bit
string
encoding
table
relevant
features
of
chromosome
chromosome
relevant
feature
f1
f2
f3
f4
the
fitness
function
has
been
calculated
after
convergence
the
relevant
feature
set
from
the
chromosome
fittest
one
has
been
chosen
to
prune
the
feature
dimension
the
vari
ous
parameters
of
ga
have
been
shown
in
table
4
number
of
correctly
recognised
character
%accuracy
fitness
function
—
total
number
of
character
following
are
the
steps
for
training
of
neural
network
extract
the
features
«+
pruning
the
feature
dimension
split
the
feature
sets
into
training
and
validation
sets
choose
the
network
configuration
which
gives
largest
validation
accuracy
inour
case
the
model
of
the
neural
network
has
two
hidden
layers
having
100
and
90
neurons
respectively
store
the
model
classification
and
recognition
ann
in
recent
years
has
proved
to
be
an
advance
tool
in
solving
classification
or
pat
tern
recognition
problems.ann
is
an
efficient
information
processing
system
which
table
parameters
of
ga
ga
parameters
value
elitism
size
population
size
240
initial
population
selection
method
roulette-wheel
crossover
probability
0.8
crossover
point
random
mutation
probability
0.01
generation
number
till
convergence
katiyar
and
mehfuz
springerplus
2016)5:357
page
12
0of
18
resembles
biological
neural
network
annss
are
robust
and
fault
tolerant
in
nature
they
process
information
in
parallel
and
they
learn
by
examples
in
this
work
to
rec
ognize
handwritten
english
character
multilayer
perceptron
has
been
used
the
archi
tecture
used
for
neural
network
is
arranged
in
layers
and
so
the
model
is
termed
as
multilayer
perceptron
it
consists
of
layer
of
input
nodes
one
or
more
layers
of
hidden
nodes
and
one
layer
of
output
nodes
we
have
designed
function
for
the
ann
classi
fier
which
provides
us
with
optimization
in
terms
of
selecting
the
best
structure
for
mlp
figure
presents
the
pseudo
code
for
selecting
best
structured
mlp
the
best
structure
includes
number
of
hidden
layers
and
number
of
neurons
present
in
hidden
layers
the
best
structure
is
found
by
calculating
the
accuracy
on
validation
set
in
each
iteration
and
storing
the
best
one
each
time
the
learning
algorithm
used
in
the
network
is
back
propagation
gradient
descent
algorithm
following
are
the
steps
for
testing
of
neural
network
extract
the
features
«+
pruning
the
feature
dimension
restore
the
model
get
the
accuracy
on
test
set
experimental
set
up
during
the
phase
of
feature
selection
process
multi
layered
feed
forward
back-propagation
neural
network
having
two
hidden
layers
with
architecture
240-100-90-6
is
used
the
length
pseudo
code/algorithm
features
are
divided
into
two
sets
as
training_feature
set
and
validation
feat
set
initialize
best_validation_accuracy=
hidden
layer
can
be
varied
from
to
n
consider
two
hidden
layer
layerl
and
layer2
wi
number
of
neurons
in
layerl(ll
number
of
neuron
in
layer2(l2
number
of
neurons
in
output
layer
0
5
initialize
l1=l2=100,k=60,0=6
6
vary
the
number
of
neurons
in
hidden
layerl
from
to
ll
and
hidden
layer2
from
to
l2
for
n=1
to
hidden
layer
fori=k
to
l1
increment
by
10
in
each
loop
for
j=k
to
l2
increment
by
10
if
i>=j&&
§>=0
i
initialize
multi-layer
perceptron
as
net
ii
perform
training
net
train(net
training_feature_set
training_bin_set
iii
perform
simulation
on
validation
set
validation_feat_set
iv
find
the
actual
labels
based
on
output
neurons
v
find
accuracy
of
validation
of
set
validation_accuracy
1f
validation_accuracy>=
best_validation_accuracy
best_validation_accuracy
validation_accuracy
end
end
end
end
7
based
on
best
configuration
found
from
step
4
initialize
neural
network
as
net
8
perform
training
net
train(net
training_feature
set,training
bin
set
9
find
accuracy
on
training
set
10.find
accuracy
on
validation
set
validation_accuracy
fig
pseudo
code
for
selection
of
best
architecture
mlp
katiyar
and
mehfuz
springerplus
2016)5:357
page
13
0of
18
of
the
feature
vector
decides
the
number
of
neurons
in
the
input
layer
the
recognition
sys
tem
consists
of
three-layered
feed
forward
nn
hanmandlu
et
al
2003
hanmandlu
and
murthy
2007
pradeep
et
al
2011
with
an
input
of
240
features
extracted
using
box
method
diagonal
distance
approach
mean
gradient
operations
approach
standard
deviation
centre
of
gravity
edge
detection
there
are
52
characters
26
for
small
and
26
for
capital
alphabets
to
be
classified
hence
bit
variable
is
required
for
the
output
thus
the
number
of
output
neurons
is
six
log
sigmoidal
logsig
is
the
activation
function
for
neurons
in
hidden
and
output
layers
it
is
very
difficult
to
choose
the
number
of
hidden
layers
and
number
of
neurons
in
hidden
layer
in
the
architecture
of
neural
network
generally
for
most
of
the
appli
cations
one
hidden
layer
is
enough
but
the
best
way
to
choose
the
number
of
neu
rons
and
number
of
hidden
layer
is
experimentation
typically
number
of
neurons
in
hidden
layer
is
determined
by
combination
of
previous
expertise
amount
of
data
available
dimensionality
complexity
of
the
problem
trial
and
error
or
validation
on
an
additional
training
dataset
polikar
2006
in
our
work
different
neural
networks
have
been
trained
with
different
numbers
of
hidden
layer
and
hidden
neurons
and
measure
the
performance
of
those
networks
as
explained
in
fig
7
we
retained
the
configuration
that
yield
the
best
performing
network
the
accuracy
on
validation
set
saturated
for
the
configuration
chosen
table
shows
the
best
mlp
architecture
for
the
feature
selection
and
table
shows
the
training
parameters
for
the
feature
selection
that
produces
the
best
results
in
our
case
figure
shows
the
structure
of
feed-forward
neural
network
the
structure
of
the
mlp
is
adaptive
in
nature
during
the
classification
phase
of
the
proposed
work
the
number
of
input
layer
neurons
have
been
changed
to
76
as
the
num
ber
of
features
have
been
reduced
to
76
after
the
implementation
of
ga
and
rest
of
the
architecture
of
the
mlp
remains
same
table
mlp
architecture
for
feature
selection
no
of
input
nodes
no
of
hidden
layers
no
of
nodes
in
hidden
no
of
nodes
in
hidden
no
of
output
layer
layer
nodes
240
100
90
table
the
training
parameters
of
mlp
for
feature
selection
training
algo
performance
function
training
epochs
learningrate
momentum
training
rithm
goal
traingdx
mean
square
error
1000
or
till
conver
adaptive
09
0.0001
gence
katiyar
and
mehfuz
springerplus
2016)5:357
page
14
of
18
input
hidden
layer
hidden
layer
output
layer
a
w2
90x1
6x1
6x90
n
100x1
90x100
6x1
fig
three
layer
neural
network
result
and
discussion
the
architecture
of
the
neural
network
consists
of
an
input
layer
two
hidden
layers
and
an
output
layer
the
number
of
neurons
are
240
100
90
and
respectively
for
input
two
hidden
and
output
layer
respectively
during
the
feature
selection
and
the
number
of
input
neurons
during
classification
stage
is
76
the
neural
network
is
trained
using
gra
dient
descent
back-propagation
algorithm
with
momentum
and
adaptive
learning
rate
the
log
sigmiodal
activation
function
is
used
to
calculate
the
output
19,145
known
data
et
of
alphabet
is
used
to
train
the
network
after
training
the
network
the
system
was
ested
using
2183
unknown
alphabet
dataset
in
this
proposed
recognition
system
seven
ifferent
approaches
of
feature
extraction
have
been
used
feature
selection
is
mostly
done
by
heuristic
or
by
intuition
for
specific
type
of
character
recognition
application
the
results
are
summarised
in
tables
7
8
9
10
11
and
12
as
seen
from
the
table
7
the
number
of
features
has
been
reduced
to
76
by
using
ga
table
shows
the
final
features
combination
that
provides
the
best
results
it
has
been
observed
in
practice
that
the
feature
selection
process
results
in
reduced
features
with
slightly
degradation
in
per
formance
kim
and
kim
2000
hence
the
process
of
feature
selection
is
applied
where
fficiency
in
terms
of
speed
along
with
space
requirement
are
important
despite
the
recognition
accuracy
been
deteriorated
this
specially
happens
in
case
of
small
features
imensional
problem
where
as
for
larger
dimensional
feature
space
accuracy
improves
table
number
of
features
networks
number
of
features
adaptive
mlp
classifier
without
feature
reduction
240
adaptive
mlp
classifier
with
feature
reduction
76
table
final
feature
combination
for
best
results
feature
set
number
of
features
box
features
23
diagonal
distance
mean
gradient
operations
13
standard
deviation
12
centre
of
gravity
edge
detection
katiyar
and
mehfuz
springerplus
2016)5:357
page
15
of
18
table
accuracy
networks
accuracy
for
capital
accuracy
alphabet
for
small
alpha
bet
adaptive
mlp
classifier
without
feature
reduction
91.56
87.49
adaptive
mlp
classifier
with
feature
reduction
94.65
91.11
table
10
computational
time
networks
testing
time
m
sec
adaptive
mlp
classifier
without
feature
reduction
43
adaptive
mlp
classifier
with
feature
reduction
25
table
11
comparisons
with
other
methods
without
feature
selection
authors
dataset
feature
extrac
classifier
accuracy
accuracy
tion
method
capital
small
alphabet
alphabet
murthy
and
han
samples
from
directional
fuzzy
logic
83.85
mandlu
2011
matlab
features
nasien
et
al
2010
nist
freeman
chain
support
vector
8846
86.00
code
machine
alietal
2010
wavelet
com
euclidean
distance
89.68
pression
hanmandlu
et
al
fusion
method
neural
network
86.00
1999
singh
and
hewitt
cedar
hough
transform
lda
67.3
2000
nearest
neighbour
63.5
vamvakas
et
al
2009
cedar
structural
fea
svm
80.19
tures
ganpathy
and
liew
self
created
multiscale
neural
87.22
2008
network
yuan
et
al
2012
unipen
convolution
neural
937
90.2
network
our
approach
cedar
hybrid
features
neural
network
91.56
87.49
table
12
comparison
with
other
methods
using
feature
selection
authors
dataset
feature
extrac
feature
classifier
accuracy
accu
tion
method
selection
capital
alpha
racy
small
bet
alphabet
chung
and
nist
gradient
pca
neural
network
93.31
yoon
1997
udlrh
90.85
de
stefano
etal
nist
hybrid
features
ga
svm
57.88
2013
mlp
6257
knn
6145
proposed
cedar
hybrid
features
ga
mlp
nn
94.65
911
method
table
shows
the
accuracy
of
the
proposed
system
is
94.65
for
capital
alphabet
and
91.11
for
small
alphabet
and
it
also
shows
that
the
accuracy
of
the
proposed
system
is
greater
than
the
original
one
where
all
the
features
have
been
considered
katiyar
and
mehfuz
springerplus
2016)5:357
page
16
of
18
the
proposed
system
performs
well
as
it
uses
less
number
of
features
and
implements
an
adaptive
mlpnn
classifier
feature
selection
using
ga
is
more
proficient
for
features
with
larger
dimension
240
in
our
case
than
smaller
dimension
this
shows
that
redun
dant
features
are
negatively
contributing
in
accuracy
of
the
classifiers
as
shown
in
table
10
the
computational
time
to
recognize
the
test
samples
of
handwritten
character
recognition
has
been
reduced
from
43
to
25
ms
as
the
number
of
features
reduces
from
240
to
76
and
also
the
proposed
system
requires
less
storage
space
reduction
in
fea
tures
dimension
is
important
as
it
improves
the
recognition
speed
kim
and
kim
2000
comparisons
of
our
handwritten
character
recognition
method
without
using
feature
selection
methodology
with
other
existing
methods
which
have
not
used
feature
selec
tion
have
been
shown
in
table
11
here
an
attempt
is
made
to
attain
high
accuracy
using
an
adaptive
mlpnn
classifier
it
is
clear
from
the
results
that
our
method
outperforms
the
other
state
of
art
methods
with
an
accuracy
of
91.56
and
87.49
respectively
for
capital
alphabet
and
small
alphabet
respectively
except
the
work
presented
by
yuan
et
al
2012
the
details
and
number
of
training
and
testing
set
are
not
clear
in
their
work
but
in
our
case
we
have
considered
whole
training
and
testing
dataset
in
the
experiment
this
superior
adaptive
structured
mlp
performance
is
due
to
the
superior
generaliza
tion
ability
of
mlp
in
high
dimensional
space
table
12
gives
the
comparative
analysis
of
the
works
which
are
using
different
feature
selections
techniques
it
is
evident
from
the
results
that
the
proposed
method
which
implies
genetic
algorithm
for
feature
selection
gives
better
results
compared
to
other
existing
methodologies
conclusions
this
paper
presents
hybrid
feature
extraction
and
ga
based
feature
selection
for
off-line
handwritten
character
recognition
by
using
adaptive
mlpnn
classifier
for
achieving
an
improved
overall
performance
on
real
world
recognition
problems
seven
approaches
of
feature
extraction
namely
box
method
diagonal
distance
method
mean
and
gradi
ent
operation
standard
deviation
centre
of
gravity
and
edge
detection
have
been
used
to
develop
an
off-line
character
recognition
system
two
different
recognition
networks
are
built
namely
adaptive
mlp
classifier
without
feature
reduction
and
adaptive
mlp
classifier
with
feature
reduction
the
network
is
trained
and
tested
on
the
cedar
cdrom-1
dataset
it
can
be
concluded
from
the
experimental
results
that
the
network
which
uses
ga
based
feature
selection
method
improves
over
all
performance
of
the
recognition
system
in
terms
of
speed
and
storage
requirement
it
has
also
been
verified
that
the
proposed
adaptive
mlp
neural
network
works
as
better
classifier
and
pro
vides
better
accuracy
authors
contributions
all
the
research
work
and
experimental
analysis
has
been
done
by
first
author
and
the
layout
and
formatting
of
the
manuscript
has
been
done
by
co-author
both
authors
read
and
approved
the
final
manuscript
author
details
department
of
electrical
engineering
jamia
millia
islamia
new
delhi
india
its
engineering
college
46
knowledge
park
greater
noida
uttar
pradesh
201308
india
acknowledgements
we
are
very
thankful
to
cedar
usa
for
their
help
as
and
when
required
we
would
also
like
to
thank
dr
rangaraja
for
giving
guide
line
in
finding
and
using
the
database
of
cedar
cdrom-1
katiyar
and
mehfuz
springerplus
2016)5:357
page
17
of
18
competing
interests
the
authors
declare
that
they
have
no
competing
interests
received
24
august
2015
accepted
12
february
2016
published
online
22
march
2016
references
ali
h
aliy
hossain
e
sultana
2010
character
recognition
using
wavelet
compression
in
proceedings
of
13th
inter
national
conference
on
computer
and
information
technology
iccit
bangladesh
pp
452-457
23-25
december
2010
arica
n
yarman-vural
ft
2001
an
overview
of
character
recognition
focused
on
off-line
handwriting
ieee
trans
syst
man
cybern
part
appl
rev
31(2):216-233
avi-ltzhak
hi
diep
ta
garland
1995
high
accuracy
optical
character
recognition
using
neural
network
with
centroid
dithering
ieee
trans
pattern
anal
mach
intell
17(2):218-223
chen
my
kundu
a
zhou
1994
off-line
handwritten
word
recognition
using
hidden
markov
model
type
stochastic
network
ieee
trans
pattern
anal
mach
intell
16:481-496
cho
sb
1999
pattern
recognition
with
neural
network
combined
by
genetic
algorithm
fuzzy
sets
syst
13:339-347
chouaib
h
cloppet
f
vincent
2012
fast
feature
selection
for
handwritten
digit
recognition
in
international
confer
ence
on
frontiers
in
handwriting
recognition
icfhr
italy
pp
485-490
chung
k
yoon
1997
performance
comparison
of
several
feature
selection
methods
based
on
node
pruning
in
handwritten
character
recognition
in
proceedings
of
fourth
international
conference
on
document
analysis
and
recognition
ulm
germany
pp
11-15
das
n
sarkar
r
basu
s
kundu
m
nasipuri
m
basu
kd
2012
genetic
algorithm
based
region
sampling
for
selection
of
local
features
in
handwritten
digit
recognition
application
appl
soft
comput
12:1592-1606
de
stefano
c
della
cioppa
a
marcelli
2002
character
pre-classification
based
on
genetic
programming
pattern
recogn
lett
23:1439-1448
de
stefano
c
fontanella
f
marrocco
c
scotto
di
freca
2013
ga-based
feature
selection
approach
with
an
applica
tion
to
handwritten
character
recognition
pattern
recogn
lett
35:130-141
feng
j
yang
y
wang
h
wang
x-m
2004
feature
selection
based
on
genetic
algorithms
and
support
vector
machines
for
handwritten
similar
chinese
characters
recognition
in
proceedings
of
the
third
interational
conference
on
machine
learning
and
cybernetics
shanghai
pp
3600-3605
26-29
august
2004
ganpathy
v
liew
kl
2008
handwritten
character
recognition
using
multiscale
neural
network
training
technique
in
proceedings
of
world
academy
of
science
engineering
and
technology
pwaset
vol
29
pp
32-37
govindan
k
shivaprasad
ap
1990
character
recognition—a
review
pattern
recogn
23(7):671-683
kim
g
kim
2000
feature
selection
using
genetic
algorithm
for
handwritten
character
recognition
in
proceedings
of
the
seventh
international
conference
on
frontiers
in
handwriting
recognition
amsterdam
pp
103-112
11-13
september
2000
hanmandlu
m
murthy
ovr
2007
fuzzy
model
based
recognition
of
handwritten
numerals
pattern
recogn
40:1840-1854
hanmandlu
m
mohan
krm
kumar
1999
neural
based
handwritten
character
recognition
in
proceeding
of
fifth
international
conference
on
document
analysis
and
recognition
icdar-99
bangalore
pp
241-244
20-22
septem
ber
1999
hanmandlu
m
mohan
krm
chakraborty
s
goyal
s
choudhury
dr
2003
unconstrained
handwritten
character
recog
nition
based
on
fuzzy
logic
pattern
recogn
36:603-623
hull
jj
1995
database
for
handwritten
text
recognition
research
eee
trans
pattern
anal
mach
intell
16(5):550-554
katiyar
g
mehfuz
2012
evolutionary
computing
techniques
in
off-line
handwritten
character
recognition
review
uacee
int
comput
sci
appl
1:133-137
lanzi
pl
1997
fast
feature
selection
with
genetic
algorithms
filter
approach
in
proceeding
of
ieee
international
conference
on
evolutionary
computation
indianapolis
in
pp
537-540
lee
sw
1995
multi
cluster
neural
network
for
totally
unconstrained
handwritten
numeral
recognition
neural
netw
8(5):783-792
lee
s-w
1996
off-line
recognition
of
totally
unconstrained
handwritten
numerals
using
multilayer
cluster
neural
net
work
|eee
trans
pattern
anal
mach
intell
18(6):648-652
lee
s-w
kim
yj
1994
off-line
recognition
of
totally
unconstrained
handwritten
numerals
using
multilayer
cluster
neural
network
in
proceedings
of
12th
iapr
international
conference
on
computer
vision
and
image
processing
jerusalem
pp
507-509
liang
z
xia
s
zhouy
zhang
l
li
2013
feature
extraction
based
on
lp-norm
generalized
principal
component
analy
sis
pattern
recognit
lett
34:1037-1045
mehfuz
s
katiyar
2012
intelligent
system
for
off-line
handwritten
character
recognition
review
int
emerg
technol
adv
eng
2:538-543
shayegan
ma
chan
cs
2012
new
approach
to
feature
selection
in
handwritten
farsi/arabic
character
recognition
in
international
conference
on
advanced
computer
science
applications
and
technologies
acsat
kuala
lumpur
pp
506-511
mori
s
suen
cy
yamamoto
1992
historical
review
of
ocr
research
and
development
proc
eee
80:1029-1057
nasien
d
haron
h
yuhaniz
ss
2010
support
vector
machine
svm
for
english
handwritten
character
recognition
in
second
international
conference
on
computer
engineering
and
applications
pp
249-252
oliveira
lsr
saburin
r
bortolozzi
f
suen
cy
2002
feature
selection
using
multi-objective
genetic
algorithms
for
hand
written
digit
recognition
ieee
pp
568-571
katiyar
and
mehfuz
springerplus
2016)5:357
page
18
of
18
parkins
ad
nandi
ak
2004
genetic
programming
techniques
for
handwritten
digit
recognition
signal
process
84:2345-2365
plamondon
r
srihari
sn
2000
on-line
and
off-line
handwriting
recognition
comprehensive
survey
ieee
trans
pattern
anal
mach
intell
22(1):63-84
polikar
2006
pattern
recognition
rowan
university
glassboro
new
jersey
wiley
encyclopaedia
of
biomedical
engi
neering
wiley
new
york
pp
1-22
pradeep
j
srinivasn
e
himavathi
2011
diagonal
based
feature
extraction
for
handwritten
alphabet
recognition
using
neural
network
int
comput
sci
technol
3(1):27-38
murthy
ovr
hanmandlu
2011
interactive
fuzzy
model
based
recognition
of
handwritten
characters
pattern
recog
nit
res
2:154-165
shrivastava
s
singh
mp
2011
performance
evaluation
of
feed-forward
neural
network
with
soft
computing
techniques
for
hand
written
english
alphabets
appl
soft
comput
11:1156-1182
singh
s
hewitt
2000
cursive
digit
and
character
recognition
on
cedar
database
in
proceedings
of
15th
international
conference
on
pattern
recognition
barcelona
3-8
september
2000
vol
2
ieee
press
new
york
pp
569-572
trier
od
jain
ak
taxt
1996
feature
extraction
methods
for
character
recognition
survey
pattern
recogn
29(4):641-662
vamvakas
g
gatos
b
perantonis
sj
2009
novel
feature
extraction
and
classification
methodology
for
the
recognition
of
historical
documents
in
ieee
10th
international
conference
on
document
analysis
and
recognition
pp
491-495
yuan
a
bai
g
jiao
l
liu
2012
offline
handwritten
english
character
recognition
based
on
convolution
neural
net
work
in
10th
iapr
international
workshop
on
document
analysis
systems
zeng
x
chen
y-w
2009
feature
selection
using
recursive
feature
elimination
for
handwritten
digit
recognition
in
proceedings
of
fifth
international
conference
on
intelligent
information
hiding
and
multimedia
signal
processing
pp
1205-1208
submit
your
manuscript
to
springeropen®
journal
and
benefit
from
convenient
online
submission
rigorous
peer
review
immediate
publication
on
acceptance
open
access
articles
freely
available
online
high
visibility
within
the
field
retaining
the
copyright
to
your
article
submit
your
next
manuscript
at
springeropen.com
