arxiv:2307.00664v1
cs.cv
jul
2023
springer
nature
2021
btex
template
cnn-biilstm
model
for
english
handwriting
recognition
comprehensive
evaluation
on
the
iam
dataset
firat
kizilirmak
and
berrin
yanikoglu
faculty
of
engineering
and
nat
sciences
sabanci
university
istanbul
tiirkiye
34956
2*center
of
excellence
in
data
analytics
verim
istanbul
tiirkiye
34956
corresponding
author(s
e-mail(s
fkizilirmak@sabanciuniv.edu
berrin@sabanciuniv.edu
abstract
we
present
cnn-bilstm
system
for
the
problem
of
offline
english
handwriting
recognition
with
extensive
evaluations
on
the
public
iam
dataset
including
the
effects
of
model
size
data
augmen
tation
and
the
lexicon
our
best
model
achieves
3.59%
cer
and
9.44%
wer
using
cnn-bilstm
network
with
ctc
layer
test
time
augmentation
with
rotation
and
shear
transformations
applied
to
the
input
image
is
proposed
to
increase
recognition
of
difficult
cases
and
found
to
reduce
the
word
error
rate
by
2.5%
points
we
also
conduct
an
error
analysis
of
our
proposed
method
on
iam
dataset
show
hard
cases
of
handwriting
images
and
explore
samples
with
erroneous
labels
we
provide
our
source
code
as
public-domain
to
foster
further
research
to
encourage
scientific
reproducibility
keywords
offline
handwriting
english
lstm
deep
learning
introduction
deep
learning
models
have
become
the
method
of
choice
for
handwriting
text
recognition
htr
problem
especially
in
the
last
decade
4
7
13
27
31
39
most
of
the
recent
works
in
offline
handwriting
recognition
have
used
convolutional
neural
networks
cnns
in
combination
with
recurrent
neural
networks
rnns
using
connec
tionist
temporal
classification
ctc
loss
func
tion
14
for
training
the
network
this
approach
allows
the
model
to
be
end-to-end
trainable
with
out
requiring
explicit
image-character
alignment
the
ctc
algorithm
maximizes
the
total
proba
bility
of
different
segmentations
over
the
output
of
the
rnn
moreover
the
ctc
algorithm
makes
many-to-one
alignment
in
which
more
than
one
input
time
frame
could
map
to
single
time
frame
at
the
output
allowing
characters
that
do
not
fit
in
single
time
step
to
be
recognized
due
to
the
success
of
attention
based
approaches
in
sequence
related
areas
2
44
more
recent
works
suggested
the
use
of
sequence-to
sequence
and
proposed
attention
based
encoder
decoder
models
22
24
31
among
these
ear
lier
methods
have
combined
cnn
with
bi-directional
rnn
as
the
encoder
and
one
directional
rnn
with
attention
mechanism
as
the
decoder
more
recent
approaches
utilized
trans
former
decoders
7
for
decoding
or
vision
trans
formers
27
as
sequence-to-sequence
architec
ture
to
exploit
their
applicability
over
handwriting
recognition
despite
recent
progress
handwriting
recogni
tion
technologies
fall
short
in
recognizing
challeng
ing
writing
styles
in
fact
there
aren’t
large
public
springer
nature
2021
ibtex
template
&70
/f
///z,e
lnaal
mdé/%@
oc\o\w
wwois
uisugl
c\ualiw&
ogj\n
\\
5)(‘(3_
q\ql‘q\
c\_}q\\x‘%
fig
the
same
text
written
by
different
people
showing
the
possible
dissimilarities
of
handwriting
examples
from
iam
dataset
datasets
to
cover
the
wide
variability
in
people’s
handwritings
some
examples
are
given
in
figure
1
this
leads
us
to
data
sparseness
problem
in
terms
of
capturing
distinct
writing
styles
in
addition
most
of
the
existing
datasets
comprise
historical
handwriting
images
making
it
imprac
tical
to
train
and
evaluate
model
for
modern
handwriting
cases
there
are
two
common
approaches
in
order
to
alleviate
the
data
sparseness
augmenting
images
at
train
time
and
generating
synthetic
handwrit
ing
images
to
pretrain
the
models
9
27
28
31
46
in
the
former
handwriting
images
are
trans
formed
to
imitate
the
same
text
as
if
it
is
written
in
different
style
by
changing
letter
shapes
while
preserving
the
readability
in
the
latter
case
synthetic
handwritten
images
are
created
this
approach
has
the
advantage
of
being
able
to
push
the
diversity
of
handwriting
styles
further
both
strategies
are
widely
used
for
introducing
differ
ent
writing
styles
to
increase
the
generalization
capacity
of
models
in
this
paper
we
have
1
conducted
compre
hensive
analysis
using
deep
learning
models
on
line-level
tam
29
dataset
2
proposed
sim
ple
yet
effective
test
time
augmentation
method
3
provided
insightful
error
analysis
regarding
dataset
related
issues
4
explored
the
state-of
art
approaches
with
their
pros/cons
and
stated
directions
for
future
work
5
made
our
train
evaluation
and
benchmarking
code
public
for
reproducibility
the
rest
of
the
paper
is
organized
as
fol
lows
first
the
related
work
regarding
the
offline
handwriting
recognition
is
presented
then
our
proposed
deep
learning
model
comes
which
is
followed
by
data
augmentation
and
synthetic
data
generation
phases
test
time
augmentation
https://github.com/firatkizilirmakk/handwriting
recognition
method
we
proposed
and
experiments
we
per
formed
afterwards
error
analysis
of
our
model
on
the
tam
dataset
and
comparison
with
the
state
of
the
art
approaches
are
given
related
work
hidden
markov
models
the
fundamental
approach
to
handwriting
recognition
prior
to
the
deep
learning
era
was
with
hidden
markov
models
hmms
35
hmms
are
doubly
statistical
mod
els
where
there
is
an
underlying
stochastic
process
governing
the
state
transitions
and
another
one
for
generating
observations
during
state
transitions
formally
the
aim
is
to
maximize
the
posterior
probability
p(s
x
taking
into
account
these
stochastic
models
of
state
transitions
and
output
generation
3
preliminary
studies
explored
offline
handwrit
ing
recognition
with
sliding
window
approach
for
feature
extraction
and
hidden
markov
mod
els
for
generating
character
or
word
sequences
5
34
they
further
supported
their
models
with
external
language
models
and
investigated
the
effects
of
lexicon
during
decoding
ctc
based
methods
connectionist
temporal
classification
ctc
method
was
introduced
for
speech
recognition
task
14
in
the
last
decade
allowing
rnn
models
to
be
trained
end-to-end
with
the
backpropagation
45
algorithm
for
sequence
classification
without
any
need
of
pre
segmented
data
the
method
was
adopted
for
handwriting
recognition
13
in
ctc
based
mod
els
1
sequence
of
image
features
are
extracted
using
sliding
window
1
pixel
wide
2
the
extracted
features
are
then
fed
to
bi-directional
lstm
bilstm
18
and
3
produced
character
sequences
via
the
ctc
layer
the
ctc
algorithm
takes
sequence
of
probability
distributions
and
generates
character
sequence
consisting
of
rec
ognizable
characters
these
models
significantly
outperformed
hmm
and
hmm-rnn
based
approaches
later
graves
et
al
applied
multi
dimensional
lstm
mdlstm
layers
instead
of
bilstm
to
incorporate
more
context
around
letters
and
to
obtain
better
transcriptions
15
with
the
rise
of
deep
learning
and
great
per
formances
achieved
by
cnn
models
on
image
processing
tasks
17
25
researchers
have
con
sidered
deep
learning
methods
for
handwriting
springer
nature
2021
etex
template
recognition
problem
as
well
instead
of
using
hand-crafted
image
features
13
15
shi
et
al
integrated
cnn
network
to
produce
more
robust
image
features
39
the
method
first
pro
cesses
input
handwriting
image
with
the
cnn
generates
sequence
of
image
features
and
passes
them
through
biilstm-ctc
layers
to
obtain
final
transcription
inspiring
from
these
bluche
et
al
proposed
gated
convolutional
model
for
computing
more
generic
image
features
4
puigcerver
37
showed
the
effectiveness
of
single
dimensional
lstm
layers
over
multi
dimensional
ones
further
dutta
et
al
9
made
com
prehensive
study
demonstrating
effects
of
data
augmentations
pretraining
and
use
of
spatial
transformer
network
stn
20
sequence-to-sequence
approaches
the
ctc
method
has
the
drawback
that
it
prevents
the
generation
of
sequences
longer
than
the
input
sequence
which
is
sequence
of
feature
maps
22
31
as
feature
maps
get
smaller
due
to
convolution
and
max
pooling
operations
the
gen
erated
sequence
becomes
shorter
which
in
turn
could
result
in
missing
transcriptions
hence
attention
based
sequence-to-sequence
methods
have
been
developed
in
order
to
overcome
the
shortcomings
of
the
ctc
and
to
leverage
their
sequence
learning
capabilities
on
handwriting
recognition
22-24
31
the
fundamental
idea
with
these
methods
is
to
use
cnn-rnn
usu
ally
bilstm
to
encode
the
input
image
as
sequence
of
features
and
then
an
attention
based
rnn
usually
an
lstm
or
gru
to
decode
the
encoded
sequence
the
overall
network
is
opti
mized
with
the
cross
entropy
loss
function
applied
over
each
frame
through
the
output
sequence
among
such
approaches
micheal
et
al
31
utilized
the
cnn-bilstm
approach
where
the
cnn
model
learned
to
encode
the
handwrit
ing
image
and
the
attention-based
lstm
model
learned
to
decode
the
encoded
representation
into
sequence
of
characters
authors
compared
differ
ent
attention
mechanisms
such
as
content-based
location-based
and
penalized
attention
and
fur
ther
combined
the
ctc
loss
along
with
the
cross
entropy
loss
to
increase
model
capabilities
kass
et
al
24
integrated
the
spatial
transformer
net
work
at
the
forefront
of
their
sequence-to-sequence
model
to
reduce
handwriting
variations
before
feeding
images
to
the
rest
of
the
architecture
apart
from
these
kang
et
al
22
incorporated
character
level
language
model
into
training
phase
where
they
feed
the
attention
based
lstm
decoder
with
the
concatenation
of
encoder
and
language
model
outputs
more
recently
transformer
44
based
models
have
been
used
due
to
their
substantial
achieve
ments
on
sequence
related
tasks
7
27
diaz
et
al
compared
ctc
and
sequence-to-sequence
approaches
experimented
with
the
transformer
decoder
and
found
the
best
performing
model
as
self-attention
encoder
with
the
ctc
decod
ing
li
et
al
on
the
other
hand
employed
the
vision
transformer
vit
8
as
an
encoder
and
vanilla
transformer
decoder
taking
advantage
of
pretrained
vit
and
transformer
decoder
they
obtained
the
state
of
the
art
results
and
further
showed
the
effectiveness
of
their
model
and
pre
training
scheme
without
any
post
processing
or
external
language
data
augmentation
synthetic
data
generation
in
addition
to
model
related
devel
opments
most
of
the
studies
proposed
solutions
for
dealing
with
data
sparseness
issue
there
are
two
common
approaches
1
applying
data
augmentation
techniques
at
train
time
for
intro
ducing
broad
range
of
handwriting
styles
2
generating
synthetic
handwriting
images
to
pro
vide
enough
and
diverse
handwriting
styles
to
deep
learning
models
affine
transformations
such
as
rotating
scal
ing
and
shearing
are
heavily
applied
and
are
shown
to
be
effective
methods
for
mimicking
hand
writing
styles
9
36
47
more
complex
augmen
tation
techniques
are
also
proposed
wigington
et
al
46
developed
distortion
method
along
with
profile
normalization
technique
to
vary
letter
shapes
which
in
turn
generates
more
dis
criminative
letter
styles
further
luo
et
al
28
proposed
to
learn
augmentation
as
joint-task
during
training
of
the
networks
the
second
approach
to
reducing
data
sparse
ness
involves
generating
synthetic
handwritten
samples
most
of
the
studies
have
generated
their
own
synthetic
data
either
in
word
or
line
level
and
experimentally
shown
their
effective
ness
while
some
have
synthesized
few
millions
of
handwriting
images
using
words
or
sentences
from
known
large
corpora
9
22
47
others
used
springer
nature
2021
ibtex
template
kq
\chlss
307
max
pooling
convolution
max
pooling
encoded
representation
>
impossible
to
say
fully
connected
ctc
fig
our
proposed
deep
learning
network
consisting
of
cnn-bilstm
models
as
encoder
and
ctc
as
decoder
synthetic
data
generated
for
scene-text
recogni
tion
problem
24
or
cropped
lines
from
pdf
files
containing
handwriting
text
27
however
though
the
above
methods
report
performance
increase
none
of
them
have
published
their
dataset
which
leaves
the
problem
unsolved
for
other
researchers
as
for
test
time
augmentation
there
are
only
few
studies
9
36
46
in
which
they
follow
sim
ilar
approaches
the
idea
is
to
augment
the
input
image
at
the
test
phase
and
then
generate
new
transcription
based
on
the
outputs
of
the
origi
nal
image
and
of
the
augmented
ones
poznanski
et
al
36
applied
36
different
transformations
on
an
image
at
test
time
retrieved
model
outputs
for
these
augmented
images
and
the
original
one
and
afterwards
took
the
mean
of
these
outputs
as
the
final
outcome
while
dutta
et
al
9
followed
the
same
approach
in
36
wigington
et
al
46
employed
20
transformations
obtained
the
corre
sponding
transcriptions
and
picked
the
final
one
with
respect
to
the
lowest
ctc
loss
value
cnn-bilstm
model
inspired
from
39
and
its
later
accomplished
successors
4
9
37
we
followed
similar
deep
learning
architecture
and
more
details
could
be
found
in
26
the
architecture
consists
of
three
fundamental
blocks
feature
extraction
from
the
input
image
using
convolutional
layers
section
3.1
processing
the
extracted
deep
features
as
sequence
using
bidirectional
lstms
section
3.2
and
producing
the
sequence
of
output
characters
with
the
help
of
ctc
decoding
section
3.3
these
modules
are
described
in
detail
below
and
the
network
structure
is
depicted
in
figure
2
3.1
feature
extraction
the
network
uses
12
convolutional
layers
with
3x3
kernels
for
feature
extraction
max
pooling
oper
ation
with
kernel
is
applied
two
times
in
total
after
the
first
two
and
following
four
con
volution
layer
blocks
the
convolution
layers
in
these
blocks
have
32
64
and
128
number
of
filters
relu
32
activation
function
and
batch
normal
ization
19
are
applied
after
each
convolution
for
faster
convergence
and
easier
training
the
cnn
network
produces
feature
map
tensor
in
the
form
of
where
corresponds
to
number
of
output
filters
or
depth
of
feature
maps
and
stand
for
height
and
width
of
feature
maps
respectively
then
we
apply
max-pooling
func
tion
over
the
height
dimension
and
interchange
the
dimensions
resulting
tensor
of
d
this
output
represents
dimensional
feature
vectors
for
sequence
of
length
more
formally
could
be
written
as
wy
wa
.
wy
indi
cating
sequence
of
time
frames
where
w
rp
for
i€
{1,2,...,t}
we
intentionally
avoided
using
deep
cnn
net
works
in
order
not
to
narrow
down
the
feature
maps
too
much
otherwise
the
ctc
algorithm
would
only
allow
producing
shorter
sequences
due
to
its
constraints
nonetheless
we
conducted
springer
nature
2021
etex
template
experiments
with
different
number
of
convo
lution
and
max-pooling
layers
and
even
tried
well-known
image
feature
extractors
like
resnet18
17
architecture
to
decide
the
baseline
model
we
explain
the
outcomes
of
these
experiments
in
section
6.2
3.2
sequence
encoding
this
phase
processes
the
sequence
of
features
crafted
by
the
feature
extraction
step
the
idea
is
to
incorporate
sequence
learning
capabilities
of
recurrent
neural
networks
to
obtain
sequences
of
features
representing
the
input
handwritten
text
better
following
4
9
37
39
we
utilised
bi
directional
lstm
model
as
well
leveraging
learned
contexts
from
both
directions
we
used
two
bilstm
layers
having
256
hidden
nodes
without
any
dropout
42
applied
we
fed
the
biilstm
layers
with
the
delivered
sequence
of
fea
tures
d
and
the
bilstm
produces
new
tensor
of
size
2
k
where
stands
for
the
hidden
dimension
size
of
the
biilstm
layer
which
is
equal
to
256
the
produced
tensor
sequence
of
feature
vectors
holds
an
encoded
representation
of
the
input
handwriting
image
in
feature
space
additionally
we
explored
bi-directional
gated
recurrent
unit
gru
6
based
models
and
conducted
experiments
with
different
number
of
recurrent
layers
and
hidden
dimension
sizes
sub
section
6.2
illustrates
the
effect
of
these
experi
ments
3.3
ctc
decoding
ing
the
input
image
through
the
first
feature
extraction
and
sequence
learn
ing
the
encoded
representation
of
the
input
is
obtained
in
the
following
form
2
k
for
mally
w1,ws,...,w
where
w
r¥
for
€{1,2,...,t}
here
stands
for
or
real
value
512
in
our
case
of
being
set
to
256
then
the
encoded
sequence
representation
x(2x
k
is
mapped
to
sequence
of
probability
distributions
over
alphabets
of
recognizable
char
acters
resulting
in
c
to
do
so
we
utilised
two
fully
connected
layers
the
first
one
is
fol
lowed
by
relu
activation
and
the
second
one
outputs
through
c
number
of
cells
further
the
softmax
function
is
applied
to
produce
sequence
of
probability
distributions
defined
over
the
alpha
bet
then
ctc
function
processes
the
output
for
labelling
the
sequence
allowing
the
whole
network
to
be
end-to-end
trainable
3.4
word
level
decoding
we
employed
three
different
decoding
methods
at
the
test
phase
to
obtain
the
final
transcription
from
the
model
output
which
is
sequence
of
probability
distributions
greedy
beam
search
12
and
word
beam
search
38
greedy
decoding
is
the
simplest
one
which
picks
the
most
likely
char
acter
at
each
time
frame
although
it
is
intuitive
to
select
character
with
the
highest
probability
it
is
not
guaranteed
to
generate
the
most
likely
transcription
sequence
instead
of
selecting
one
character
at
time
beam
search
keeps
most
likely
transcriptions
at
each
time
frame
and
produces
transcription
with
the
highest
score
among
these
alternatives
12
word
beam
search
wbs
on
the
other
hand
is
an
extension
of
the
beam
search
which
constrains
words
to
be
in
given
lexicon
and
allows
non-word
characters
to
occur
inside
words
38
moreover
the
algorithm
incorporates
2-gram
word-level
language
model
for
scoring
words
through
decod
ing
we
used
wbs
algorithm
to
output
the
final
transcription
set
beam
width
as
150
and
con
figured
word
beam
search
to
utilize
the
2-gram
language
model
data
augmentation
synthetic
data
generation
4.1
public-domain
datasets
the
handwriting
recognition
domain
lacks
high
quality
open-access
datasets
with
high
number
of
samples
even
though
the
problem
has
been
studied
for
decades
there
are
few
common
datasets
that
contain
full
sentences
namely
itam
rimes
bentham
and
washington
10
16
29
43
where
the
last
two
consist
of
only
historical
hand
writing
images
which
are
not
suitable
for
modern
cases
tam
dataset
was
first
published
in
1999
29
and
still
is
the
most
commonly
used
english
hand
writing
dataset
it
contains
handwriting
texts
in
english
written
by
657
different
people
there
are
1,539
scanned
pages
partitioned
into
10,373
springer
nature
2021
ibtex
template
visual
a
oc\d\w
wt
disual
gualities
aja/h
st
the
ofsugl
quaﬂ/fkf
og’\a\w
qualities
agaw
1%
is
visual
qualitice
b
aqa\m
iv
18
the
gisual
qualities
0@
yo
wvsual
quaties
fig
original
image
along
with
the
augmented
samples
a
original
image
b
images
augmented
by
affine
trans
form
first
two
lines
are
sheared
the
last
one
is
rotated
c
images
applied
elastic
distortion
and
perspective
transform
from
geometric
conversions
labelled
text
lines
and
79
different
characters
to
the
best
of
our
knowledge
there
is
no
other
public
dataset
in
english
with
non-historical
and
line-level
handwriting
images
rimes
dataset
16
consist
of
french
handwrit
ing
and
has
been
used
for
evaluating
generaliza
tion
abilities
of
models
for
long
time
however
we
have
not
been
able
to
access
to
the
dataset
using
official
channels
and
their
websites
as
also
indicated
here
2
therefore
our
experiments
will
not
include
results
on
this
dataset
due
to
this
data
sparseness
current
methods
usually
exploit
data
augmentation
and
synthetic
data
generation
techniques
fundamental
idea
is
to
alleviate
the
lack
of
data
problems
and
present
various
handwriting
styles
for
better
generaliza
tion
yet
these
works
have
not
published
the
synthetic
datasets
they
have
crafted
which
in
turn
disallows
common
evaluation
protocol
4.2
data
augmentation
although
data
augmentation
for
visual
tasks
has
been
explored
extensively
40
there
are
cou
ple
of
studies
that
proposed
novel
approaches
to
augment
handwriting
images
28
41
46
while
others
utilized
common
methods
such
as
affine
transformations
9
36
46
47
zhttps://github.com/jpuigcerver
/laia/issues/44
following
9
36
47
we
employed
affine
con
versions
including
shear
and
rotation
to
generate
natural
looking
handwriting
images
moreover
we
applied
elastic
distortion
46
and
geometric
trans
formations
28
to
further
increase
the
handwriting
variability
augmented
examples
with
these
con
versions
are
displayed
in
figure
3
shear
is
linear
affine
transformation
that
takes
point
z,y
r
and
maps
it
to
z
ky,y
r2
if
it
conducts
horizontal
conversion
here
denotes
the
scaling
factor
determining
how
many
pixels
to
move
in
an
image
rotation
is
another
linear
affine
transformation
that
rotates
point
z,y
in
the
counter-clockwise
direction
by
degree
using
these
shear
and
rotation
trans
formations
makes
it
possible
to
mimic
slanted
handwriting
styles
as
illustrated
in
figure
b
elastic
distortion
on
the
other
hand
is
non
inear
transformation
that
elastically
changes
the
shape
of
letter
we
used
the
method
in
41
where
displacement
fields
az
and
ay
are
sampled
from
probability
distribution
first
they
sample
and
positions
of
the
field
from
uniform
distribu
ion
between
1,+1
then
convolve
these
fields
separately
with
1-dimensional
gaussian
kernel
of
standard
deviation
finally
the
fields
get
mul
iplicated
by
value
to
determine
the
distortion
intensity
overall
the
method
is
able
to
distort
handwriting
letters
using
and
parameters
we
also
use
geometric
transformations
as
proposed
in
28
which
transform
an
image
by
moving
set
of
predefined
points
to
new
posi
ions
the
movement
of
the
points
is
determined
via
an
agent
network
where
this
transformation
method
is
optimized
jointly
with
text
recogni
ion
module
to
craft
readable
yet
hard
samples
we
used
closed-form
versions
of
their
augmenta
namely
distortion
stretch
and
perspective
and
grouped
them
under
the
name
of
geometric
ransformations
these
transformations
were
applied
to
the
input
image
more
than
once
with
different
param
eters
to
generate
distinct
handwriting
styles
we
decided
on
the
range
of
parameters
of
the
augmen
tation
methods
by
visual
inspection
we
deformed
the
letter
shapes
to
some
degree
while
considering
the
readability
of
the
handwriting
during
train
ing
input
images
undergo
transformation
with
ions
3publicly
shared
in
https://github.com/canjie-luo/text
image-augmentation
springer
nature
2021
etex
template
the
route
to
each
story
location
on
+the
game
be()bv\
c\eve\o?mew
2010
cavyying
while
it
retained
the
standard
features
of
second
earop
a-n
wor
who
pe//
orm
secret
black
bolh
vebwened
fvom
previous
enteies
af
ong
with
such
as
making
the
game
more
for
fig
examples
of
synthetically
generated
handwriting
line
images
probability
0.5
which
makes
it
practically
impossible
to
introduce
the
same
image
again
we
trained
our
base
model
with
and
with
out
these
augmentations
in
order
to
evaluate
their
effects
outcomes
of
these
experiments
are
given
in
detail
in
section
6.3
4.3
synthetic
data
generation
many
state-of-art
systems
craft
their
synthetic
dataset
following
similar
steps
such
as
employing
texts
written
in
widely
used
large
corpora
1
11
or
crawling
text
from
the
internet
22
to
synthesize
artificially
written
handwritten
images
we
combined
wikitext-2
30
brown
11
and
training
text
of
tam
dataset
which
cor
responds
to
lob
corpus
1
as
the
corpus
to
generate
images
from
then
the
texts
were
pre
processed
to
have
unified
form
with
correctly
tokenized
words
sentences
were
tokenized
into
words
and
punctuation
was
removed
at
most
word-sentences
are
picked
to
generate
lines
syn
thetically
more
than
200
handwriting
truetype
fonts
were
collected
from
the
internet
and
then
utilized
to
synthesize
images
we
took
advantage
of
the
trdg
tool
to
generate
synthetic
images
using
these
corpora
and
fonts
overall
we
have
generated
almost
2.5
million
synthetic
handwrit
ing
image
lines
example
images
are
illustrated
in
figure
4
https://github.com/belval/textrecognitiondatagenerator
test
time
augmentation
based
on
our
initial
observation
that
large
majority
of
character
and
word
errors
originated
from
small
portion
of
text
lines
coupled
with
the
fact
that
text
lines
may
be
recognized
better
if
they
were
not
slanted
or
rotated
we
hypothesized
that
test
time
augmentation
would
help
for
the
offline
handwriting
recognition
prob
lem
the
idea
of
the
test
time
augmentation
is
to
apply
transformations
to
an
input
handwrit
ing
image
at
the
test
phase
obtain
transcriptions
of
the
corresponding
augmented
images
and
then
decide
on
the
best
decoding
the
idea
was
used
before
in
9
36
46
however
we
evaluated
differ
ent
methods
for
choosing
or
constructing
the
final
recognition
output
given
the
recognition
outputs
of
different
augmentations
while
it
is
simple
and
effective
idea
test
time
augmentation
is
not
widely
used
or
evaluated
due
to
the
added
decod
ing
time
however
the
method
could
be
preferable
in
the
case
of
batch
processing
where
time
is
not
too
critical
for
test
augmentation
we
applied
16
different
shear
and
rotation
augmentations
in
total
to
the
original
image
at
test
time
and
retrieved
transcrip
tions
of
both
augmented
images
and
the
original
image
we
then
obtained
the
overall
score
by
com
bining
the
optical
score
of
the
deep
learning
model
op
and
language
model
score
lm
over
the
decoded
transcription
score
a
opy
w
lmj
1
where
op
is
obtained
from
the
wbs
decoding
algorithm
and
lm
denotes
the
language
model
springer
nature
2021
ibtex
template
oal
at
3003
darb
s-ioatit's
good
start
04
5.55
{06
17.77
||
12.88
»
optical
score
»{
lm
score
final
score
bal
1%
jvaod
harb
bat
it's
good
start
sheared
0.3
degree
b
04
12.13
0.6/
15.87
||=
14.37
optical
score
lm
score
final
score
bal
3003
darb
but
it's
good
start
rotated
2.5
degree
(
04
4.50
0.6/
10.31
||=
7.98
/
optical
score
lm
score
{final
score
fig
an
example
application
of
the
scoring
transcriptions
a
output
of
the
original
image
is
scored
using
the
equation
1
the
optical
score
is
obtained
from
the
deep
learning
network
the
language
model
score
is
computed
using
the
4-gram
language
model
b
and
c
shows
the
scoring
steps
of
the
transformed
images
the
output
with
the
lowest
final
score
is
picked
as
the
final
output
which
is
the
correct
transcription
of
the
handwriting
score
obtained
from
the
below
defined
4-gram
language
model
then
the
transcription
with
the
highest
score
was
picked
as
the
final
outcome
through
the
experiments
we
fit
values
for
and
w
we
trained
the
language
model
as
4-gram
model
on
wikitext-103
30
corpus
with
kneser
ney
smoothing
33
using
kenlm
tool
before
training
the
language
model
we
applied
prepro
cessing
steps
including
tokenization
of
the
words
lowering
the
letters
and
removing
punctuation
figure
illustrates
the
proposed
method
in
simplified
fashion
for
each
image
original
or
transformed
the
optical
score
produced
by
the
model
for
the
image
and
the
language
model
score
shttps://github.com/kpu/kenlm
computed
for
the
corresponding
transcription
are
combined
using
the
above-defined
formula
the
best
transcription
with
the
highest
score
7.98
for
the
example
in
the
figure
is
picked
as
the
final
output
which
is
the
correct
decoding
obtained
from
the
image
rotated
by
2.5
degrees
for
this
case
in
addition
to
the
simplicity
of
this
method
it
is
applicable
to
any
network
generating
charac
ter
sequences
from
handwriting
images
further
the
method
achieves
superior
results
see
table
9
once
the
best
decoding
is
selected
with
respect
to
the
lowest
error
as
if
an
oracle
telling
the
truth
this
suggests
that
better
scoring
function
will
yield
greater
success
springer
nature
2021
etex
template
experiments
we
have
run
comprehensive
evaluations
including
the
input
scaling
6.1
the
baseline
architecture
6.2
the
data
augmentation
6.3
pretraining
with
synthetic
data
6.4
effect
of
lexicon
let
ter
case
and
punctuation
6.5
and
the
test
time
augmentation
6.6
through
the
experiments
models
were
trained
and
evaluated
on
the
corresponding
aachen
splits
of
the
tam
dataset
training
was
set
to
last
by
200
epochs
at
most
and
stopped
after
10
epochs
of
non-decreasing
validation
loss
initial
learning
rate
was
le
for
most
of
the
experiments
though
it
was
tailored
in
some
cases
rmsprop
optimizer
was
used
with
weight
decay
being
set
to
le-5
batch
size
was
kept
fixed
at
16
we
assessed
the
performance
of
the
models
using
character
error
rate
cer
and
word
error
rate
wer
which
corresponds
to
normalized
levenshtein
distances
between
the
predicted
and
ground
truth
character
sequences
though
we
uti
lized
the
three
decoding
methods
we
share
cer
and
wer
scores
from
the
word
beam
search
algorithm
in
the
tables
6.1
input
scaling
input
images
were
resized
to
100
960
before
feed
ing
to
recognition
models
it
is
intuitive
to
keep
image
height
as
fixed
and
resize
the
width
pre
serving
the
aspect
ratio
however
in
our
prelimi
nary
experiments
we
acquired
worse
performance
with
this
approach
and
other
fixed
image
sizes
we
also
tried
keeping
images
as
is
and
feeding
to
models
one-by-one
as
keeping
batch
size
set
to
1
yet
this
approach
was
neither
effective
nor
effi
cient
thus
we
resized
images
to
100
960
and
feed
through
the
deep
learning
network
6.2
model
experiments
our
preliminary
experiments
were
designed
to
decide
on
the
baseline
model
that
would
be
used
in
upcoming
experiments
inspired
from
4
9
37
39
we
followed
similar
cnn-rnn
ctc
architecture
as
explained
in
section
3
we
explored
combinations
of
cnn
and
rnn
mod
els
with
different
hyperparameters
through
the
experiments
backbone
we
first
experimented
with
the
num
ber
of
convolution
layers
in
the
cnn
backbone
network
keeping
the
rest
of
the
layers
fixed
we
employed
separate
cnn
networks
with
8
10
12
and
14
layer
convolutions
while
applying
or
max
pooling
operations
in
addition
smaller
resnet
17
variant
resnetl8
was
utilized
to
experiment
with
deeper
model
compared
to
previous
ones
for
the
sequence
encoding
two
layered
bi-directional
lstm
network
was
used
with
hidden
dimension
of
256
during
these
backbone
and
sequence
encoding
experiments
no
data
augmentation
was
applied
to
measure
the
direct
effect
of
these
model
choices
table
impact
of
backbone
configuration
on
the
iam
validation
split
backbone
max
pooling
cer
wer
conv
layers
5.49
16.34
10
conv
layers
5.95
17.17
12
conv
layers
01
15.14
14
conv
layers
5.37
15.51
resnet18
default
6.08
18.27
as
displayed
in
table
1
12-layer
cnn
net
work
with
two
max
pooling
operations
surpassed
the
other
ones
though
there
is
no
significant
performance
gap
shallower
or
deeper
the
model
obtains
lower
scores
therefore
we
preferred
con
tinuing
with
the
best
scored
model
with
the
least
parameters
and
built
the
baseline
model
on
top
of
the
12-layer
cnn
network
sequence
encoding
after
deciding
on
the
backbone
network
our
next
experiment
is
to
select
sequence-encoder
model
to
this
end
we
evaluated
the
performance
of
bi-directional
lstm
and
gru
networks
we
varied
the
number
of
recurrent
layers
and
hidden
layer
sizes
of
these
deep
learning
networks
table
illustrates
the
model
configurations
and
the
corresponding
error
rates
on
the
validation
split
of
the
tam
dataset
two
recurrent
layers
fit
better
for
this
prob
lem
as
seen
in
table
2
models
competed
with
different
hidden
dimension
sizes
yet
there
was
no
exact
winner
of
this
experiment
however
we
intended
to
keep
the
model
simple
while
preserv
ing
its
capabilities
thus
we
preferred
to
complete
springer
nature
2021
ibtex
template
the
baseline
model
with
2-layered
bilstm
hav
ing
hidden
dimensions
of
256
which
outperformed
the
other
networks
the
rest
of
the
experiments
were
built
upon
this
baseline
model
consisting
of
12
layered
cnn
with
two
max
pooling
functions
and
two-layered
bilstm
with
256
hidden
dimensions
followed
by
ctc
layer
table
performance
of
sequence
encoding
models
biilstm
and
bigru
with
different
configurations
on
the
tiam
validation
split
here
the
backbone
network
is
the
one
with
the
12
convolutional
layers
and
max-pooling
operations
as
displayed
in
table
1
hidden
rnn
model
layers
dim
size
cer
wer
256
1.95
15.42
512
5.26
bilstm
256
1.62
14.62
512
1.93
14.93
256
5.07
15.64
512
5.24
16.14
256
5.27
16.54
512
4.90
15.48
bigru
256
5.01
512
4.85
256
5.05
512
5.70
6.3
data
augmentation
after
establishing
the
baseline
model
we
explored
the
effect
of
data
augmentation
techniques
which
are
described
in
section
4
the
transformations
were
either
applied
separately
or
in
combination
as
shown
in
table
3
to
assess
the
effect
of
each
method
we
only
performed
one
conversion
on
an
image
so
as
not
to
deform
handwritings
too
much
and
it
was
only
applied
with
probability
0.5
we
determined
to
parameters
of
the
transfor
mations
by
visually
inspecting
augmented
images
for
the
shear
transformation
is
sampled
from
uniform
distribution
between
0.6
and
+0.6
with
fixed
random
seed
to
apply
the
same
conver
sions
through
all
the
experiments
rotation
angle
was
kept
in
small
degrees
from
2.5
to
+2.5
to
mimic
slanted
handwritings
while
keeping
letters
table
effect
of
train
time
data
augmentations
applied
in
separate
and
in
combination
using
the
baseline
network
defined
above
for
the
combined
augmentations
only
one
of
the
transformations
is
used
on
an
image
to
keep
readability
of
handwritings
while
deforming
handwriting
styles
an
augmentation
is
applied
with
probability
0.5
augmentation
method
cer
wer
baseline
from
table
4.62
14.62
no
augmentation
shear
4.28
13.44
rotate
4.67
14.06
elastic
4.48
14.72
geometric
4.52
14.29
shear
elastic
geometric
4.20
13.18
shear
rotate
elastic
4.17
13.21
shear
rotate
elastic
geometric
4.06
13.02
inside
image
borders
elastic
distortion
variables
were
picked
from
the
following
sets
{3,4}
{15,20}
once
the
parameters
set
we
trained
the
models
using
these
augmentations
and
evaluated
without
any
transformation
applied
shear
conversion
is
the
most
convenient
way
to
mimic
handwriting
thereby
the
model
with
only
shear
augmentation
obtained
better
scores
com
pared
to
other
single
transformation
experiments
as
revealed
in
table
3
even
though
the
other
methods
were
not
as
effective
on
their
own
their
combination
achieved
better
performance
due
to
generating
more
diverse
handwriting
styles
as
observed
over
the
validation
set
hence
we
per
formed
the
next
set
of
experiments
using
these
augmentations
at
train
time
6.4
pretraining
with
synthetic
data
generating
synthetic
handwriting
images
is
another
commonly
used
strategy
to
reduce
the
data
sparseness
and
increase
the
generalization
capacity
of
models
section
describes
in
detail
how
we
produced
images
from
the
utilized
corpora
using
an
online
image
generation
tool
we
firstly
trained
the
baseline
deep
learn
ing
network
on
the
generated
data
consisting
of
almost
2.5
million
synthetic
handwriting
images
we
applied
the
data
augmentation
methods
explained
in
section
4
to
the
synthetic
images
in
order
to
push
the
diversity
further
the
synthetic
11
springer
nature
2021
etex
template
dataset
was
not
split
into
validation
or
test
parti
tions
the
model
was
directly
trained
on
the
whole
dataset
by
epochs
table
results
of
our
pretrained
deep
learning
model
on
the
iam
validation
and
test
splits
linear
layer
parameters
of
the
output
linear
layers
are
updated
while
fine-tuning
all
layers
all
the
parameters
are
updated
validation
test
pretrainin
cer
wer
cer
wer
%
%
%
%
baseline
from
table
no
pretraining
4.06
13.02
5.20
14.86
pretrained
linear
layer
4.21
14.16
5.44
15.58
all
layers
3.88
12.71
5.05
14.46
we
reduced
the
character
errors
by
around
0.15%
and
word
errors
around
0.4%
from
5.20%
to
5.06%
for
character
errors
and
from
14.86%
to
14.46%
for
word
errors
by
only
pretrain
ing
the
model
on
more
than
million
synthetic
handwriting
images
however
there
is
room
for
improvement
once
there
is
more
synthetic
and
natural
handwriting
data
for
pretraining
and
fine
tuning
we
performed
the
next
set
of
experiments
using
this
pretrained
model
afterwards
the
pretrained
network
was
fine
tuned
on
the
tam
dataset
train
partitions
in
two
ways
1
freezing
all
the
parameters
of
the
model
except
the
output
linear
layers
2
updating
all
the
parameters
then
the
fine-tuned
model
was
evaluated
on
the
tam
validation
and
test
parti
tions
and
the
corresponding
scores
are
given
in
table
4
updating
only
the
parameters
of
the
final
lin
ear
layers
did
not
reveal
better
scores
as
expected
due
to
the
difference
in
handwriting
styles
between
synthetic
and
natural
ones
hence
we
adopted
pretraining
all
layers
in
the
remainder
of
the
experiments
the
results
of
this
experiment
are
shown
in
table
4
6.5
effect
of
lexicon
letter
case
and
punctuation
we
decoded
model
outputs
using
three
different
methods
greedy
beam
search
and
word
beam
search
and
gave
the
best
results
obtained
by
the
word
beam
search
algorithm
in
all
result
tables
we
used
greedy
and
beam
search
methods
as
is
in
other
words
without
adding
an
external
language
model
or
considering
lexicon
during
decod
ing
however
word
beam
search
builds
prefix
tree
from
corpus
i.e
lexicon
to
keep
decoded
words
in
the
lexicon
therefore
we
explored
the
effect
of
lexicon
size
and
out-of-vocabulary
rate
on
decoding
performance
we
experimented
with
three
different
english
corpora
and
their
combinations
for
building
the
lexicon
the
base
lexicon
consists
of
the
texts
from
the
tam
training
partition
which
is
part
of
the
lob
corpus
1
on
top
of
it
we
appended
the
brown
corpus
which
is
million-word
english
text
corpus
consisting
of
texts
from
15
different
categories
we
also
added
the
wikitext-2
corpus
comprising
over
two
million
english
words
fur
ther
we
assessed
their
combination
as
well
as
the
validation
partition
of
the
iam
dataset
the
lex
icon
built
upon
the
tam
validation
split
has
zero
out-of-vocabulary
rate
which
is
not
possible
for
real-time
scenarios
yet
it
underlines
the
effect
of
the
lexicon
table
reflection
of
lexicon
size
with
number
of
unique
words
after
tokenization
lowering
and
discarding
punctuation
and
out-of-vocabulary
oov
rates
on
errors
stands
for
the
brown
corpus
and
w2
for
the
wikitext2
corpus
oov
cer
wer
lexicon
words
rate
%
%
baseline
from
table
iam
train
7845
054
388
1271
57.606
0.15
3.49
11.77
w2
60.244
0.21
3.56
11.92
w2
82.449
0.13
3.46
11.70
iam
validation
2.251
0.00
2.2
6.35
the
error
rate
depends
on
the
context
of
the
words
in
the
lexicon
as
the
rate
of
the
out
of
vocabulary
oov
words
decreased
the
error
rates
gets
reduced
as
well
as
illustrated
in
table
5
in
normal
test
scenario
it
is
not
possible
to
contain
all
likely
words
in
lexicon
which
is
the
tam
test
case
in
the
table
nonetheless
most
of
the
time
we
obtained
lower
error
rates
when
using
larger
lexicons
however
one
needs
to
account
the
trade-off
between
the
running
time
with
bigger
lexicon
and
obtained
performance
we
preferred
springer
nature
2021
ibtex
template
going
with
the
lexicon
consisting
of
train
partition
of
tam
brown
and
wikitext-2
since
there
is
no
significant
difference
of
running
time
compared
to
smaller
lexicons
in
table
5
the
error
rate
depends
on
the
context
of
the
words
in
the
lexicon
as
the
rate
of
the
out
of
vocabulary
oov
words
decreased
the
error
rates
gets
reduced
as
well
as
illustrated
in
table
5
in
normal
test
scenario
it
is
not
possible
to
contain
all
likely
words
in
lexicon
which
is
the
tam
test
case
in
the
table
nonetheless
most
of
the
time
bigger
the
lexicon
is
lower
the
errors
achieved
however
one
needs
to
account
the
trade-off
between
the
running
time
with
bigger
lexicon
and
obtained
performance
we
preferred
going
with
the
lexicon
consisting
of
train
partition
of
tam
brown
and
wikitext-2
since
there
was
no
significant
difference
of
running
time
compared
to
smaller
lexicons
in
table
5
we
decoded
and
compared
the
transcriptions
with
the
ground
truth
text
in
case-sensitive
manner
and
also
counting
punctuation
errors
however
some
work
in
the
literature
report
that
they
generated
case
insensitive
text
without
any
punctuation
9
46
while
others
do
not
specify
this
as
matter
of
fact
the
iam
dataset
contains
sentences
with
several
quotes
and
punctuation
around
them
as
this
is
an
important
distinc
tion
we
performed
experiments
considering
both
strategies
with
results
given
in
table
6
however
unless
otherwise
stated
explicitly
we
shared
all
the
errors
measured
with
case
sensitive
letters
and
punctuation
through
the
tables
table
effect
of
the
letter
case
and
the
punctuation
when
decoding
over
the
validation
split
of
the
iam
dataset
decoding
method
up
to
this
experiment
involved
case
sensitive
letters
with
punctuation
cer
wer
case
punctuation
%
%
baseline
case
sensitive
punctuation
3.46
11.70
case
insensitive
punctuation
3.16
10.58
case
insensitive
no
punctuation
2.87
8.27
6.6
test
time
augmentation
test
time
augmentation
is
simple
and
effective
technique
which
offers
feasible
time
complex
ity
for
batch
processes
we
described
our
method
table
validation
and
test
scores
with
and
without
test
time
augmentation
in
case
sensitive
recognition
as
well
as
ignoring
punctuation
mistakes
oracle
indicates
the
case
where
the
final
transcription
was
selected
so
as
to
minimize
the
character
error
among
all
transcriptions
obtained
with
test
augmentation
validation
test
test
time
cer
wer
cer
wer
augmentation
%
%
%
%
3.46
11.70
4.80
13.85
3.22
10.63
4.37
12.03
oracle
2.28
8.54
3.02
9.35
of
using
test
time
augmentation
to
obtain
better
transcriptions
in
section
5
once
the
final
transcription
is
obtained
it
is
compared
with
the
ground
truth
character
sequence
and
error
score
in
terms
of
cer
and
wer
metrics
are
measured
we
assessed
the
pro
posed
test
time
augmentation
method
on
ignoring
errors
involving
case
or
punctuation
mistakes
to
gain
further
insight
table
shows
that
applying
test
time
augmen
tation
reduced
the
character
errors
by
almost
0.5%
and
word
errors
by
around
2%
when
decoding
with
case-sensitive
letters
and
punctuation
the
error
rate
gets
decreased
further
almost
1%
for
character
errors
and
2.5%
for
word
errors
when
decoding
with
case
insensitive
letters
without
punctuation
as
displayed
in
table
8
in
addition
to
our
scoring
function
we
per
formed
test
time
augmentation
and
selected
the
final
transcription
with
respect
to
the
lowest
cer
score
among
all
transcriptions
we
named
this
method
as
oracle
since
it
knows
in
advance
the
error
due
to
the
comparison
with
the
ground
truth
sequence
which
is
not
possible
in
real
life
how
ever
our
aim
was
to
show
the
how
much
gain
is
possible
with
this
oracle
method
as
tables
table
validation
and
test
scores
with
and
without
test
time
augmentation
considering
case
insensitive
letters
ignoring
punctuation
errors
validation
test
test
time
cer
wer
cer
wer
augmentation
%
%
%
%
3.2
11.29
4.38
12.00
2.84
9.05
3.59
9.44
oracle
1.61
6.42
2.63
7.74
13
springer
nature
2021
etex
template
7,8
indicates
there
is
room
for
improvement
once
better
scoring
function
is
employed
moreover
this
strategy
is
applicable
to
any
model
generat
ing
character
sequences
from
handwriting
images
which
makes
it
considerable
for
other
models
as
well
we
also
analyzed
the
time
running
times
with
decoding
of
original
images
we
run
our
proposed
methods
on
two
different
machines
with
the
fol
lowing
configurations
1
amd
ryzen
3970x
64
gb
ram
with
geforce
rtx
3090
2
intel
i7
10700k
32
gb
ram
with
gefore
rtx
3080
the
time
taken
for
each
image
was
measured
and
its
average
with
the
standard
deviation
for
all
the
samples
in
the
iam
test
partition
is
computed
for
both
of
our
methods
as
shared
in
table
9
even
though
this
test
time
augmentation
method
slows
down
obtaining
the
final
transcription
it
could
be
preferred
for
batch
processing
of
documents
when
there
is
no
real
time
requirements
additionally
better
scoring
function
would
reveal
greater
suc
cess
without
needing
any
more
model
parameters
or
more
data
table
running
times
of
test
time
augmentation
method
on
two
different
machines
with
cpu
gpu
options
mean
and
standard
deviation
of
the
elapsed
time
over
the
iam
test
partition
original
with
test
time
time
s
aug
time
s
machine
proc.essmg
mean
std
mean
std
device
pc1
cpu
2.58
1.03
2146
4.08
gpu
2.27
0.98
19.33
3.84
pc
cpu
3.64
1.12
2554
4.56
gpu
3.28
1.02
2476
4.21
error
analysis
up
to
this
point
we
measured
system
performance
in
terms
of
cer
and
wer
metrics
and
computed
their
mean
over
the
iam
test
partition
once
we
examined
the
erroneous
cases
we
found
out
that
lot
of
the
errors
are
contributed
by
smaller
number
of
text
lines
in
this
section
we
provide
analysis
in
terms
of
the
error
distribution
explore
difficult
sam
ples
along
with
possible
ways
to
overcome
these
challenging
handwriting
samples
and
share
mis
labelled
example
lines
from
the
iam
dataset
we
analyzed
the
outputs
of
the
best
models
without
the
test
time
augmentation
for
simplicity
one
can
see
in
figure
that
in
42%
of
all
the
lines
all
the
characters
were
recognized
correctly
and
in
80.89%
of
all
the
images
in
the
iam
test
set
there
were
at
most
character
mistakes
note
that
the
dataset
has
an
average
of
35.2
characters
per
line
image
with
an
8.72
standard
deviation
this
is
rather
surprising
statistics
which
we
believe
can
indicate
certain
future
research
direc
tions
based
on
this
observation
we
focused
on
test
time
augmentation
for
example
similarly
the
model
produced
at
most
one
incorrect
word
in
68.75%
of
all
the
samples
in
the
test
split
where
the
mean
number
of
words
in
lines
is
8.90
some
of
the
most
challenging
writing
samples
are
given
in
figure
7
the
figure
shows
exam
ples
from
tam
test
dataset
where
our
model
made
at
least
five
character
errors
which
corresponds
to
7%
of
the
test
set
samples
note
that
these
handwritings
are
difficult
for
people
as
well
furthermore
the
iam
dataset
contains
par
tially
or
totally
wrong
ground
truth
labels
which
in
fact
affects
the
both
training
and
testing
phases
therefore
we
found
and
corrected
the
erroneous
cases
on
the
tam
test
split
in
order
to
evaluate
better
example
erroneous
lines
along
with
their
issues
are
presented
in
the
appendix
a
we
will
share
the
new
fixed
metadata
of
the
test
split
on
the
link
©
comparison
with
the
state
of
the
art
our
approach
is
compared
to
state-of-art
methods
with
varying
characteristics
as
shown
in
table
10
however
it
should
be
noted
that
direct
compari
son
of
the
models
may
not
very
meaningful
due
to
differences
or
omissions
in
training
or
testing
criteria
our
model
is
able
to
compete
with
the
sim
ilar
approaches
proposed
in
4
47
however
we
were
not
able
to
fully
duplicate
their
results
due
to
the
differences
including
1
extra
data
they
used
in
training
2
the
language
model
they
employed
to
support
the
deep
learning
network
shttps://github.com/firatkizilirmakk/handwriting
recognition
springer
nature
2021
ibtex
template
ppunjon
sussuiose
65°
vll
sam
ks
coat
lep
9°€
vlt
sem
2otm
umorgg
iuas
vi
d1d
wist
nno
smo
g8°€t
08'¥
0st/mq
stm
qlt
9t~
apooin
weas-g
o1qnd
reusejuy
1o
2
ze1a
qt'ee
9t~
apooin
weas-g
onqng
dilo
mv
jios
2
z7e1a
68°c
89g
01/mq
wreag
usks
vi
iouliofsurl
22
11
tre
vee
0t/mq
wresg
quds
vi
touoysuely
22
11
gpat
297
00t
apoord
qyuss
vi
wuuojsuely
12
buey
87
91/mq
wesg
vi
wy
nlst
inlst
nno
1€
pewonn
99'8
£0
091/m9
sem
07t
umorg
qauks
nv
dl
wist
nnd
£7
oerx
<ot
ze
gl0
30g
int
ureas-l
bn
nv
dl
nnh¥od
v
ovonig
mhem
mad
surpooa(y
woorxer
73
int
jog
urea
1poda
topooug
sty
uoryenjound
suliopisuod
moyiim
sutpoisp
oy
sijousp
joun
jon
pue
suipodop
sai}isusui-osld
10
spurys
suasujase
syiomjou
jurures
deop
o
jo
suor[iur
ur
siojourered
s[qeuiel
jo
i9quinu
oyy
st
j#
yipim
weaq
dyy
st
pue
wjlios[e
yoiess
weaq
piom
1
s9j0uap
i0h
oousnbos
1ojoereyd
ogul
sindin0
ji0mjou
spooap
0
pissn
st
poypou
yiiym
$9)eiiput
sutpodd
suiposep
suump
lue
j1
pesn
sureq
uojixs
oy}
pue
ppowr
afensue
a1}
sejousp
uooixst
29
soydeoidde
jre-oy)-jo-oyers
oy
yym
yoroidde
jo
uostredwio
qt
s[qel
springer
nature
2021
etex
template
cumulative
character
errors
iam
cumulative
word
errors
jam
3000
42.06%
42.06%
2500
59.62%
2500
68.75%
1245%
84.49%
2000
8089%
2000ttt
—
92.80%
87.72%
—
96.40%
1500
9122%
1500
—
98.46%
93.62%+
99.25%
f=
1000
1000
500
500
10
12
14
16
10
12
14
16
cer
<=
wer
<=
a
b
fig
cumulative
character
and
word
error
rates
obtained
with
the
baseline
model
on
the
iam
dataset
a
illustrates
cumulative
character
errors
example
all
the
characters
are
predicted
correctly
in
42%
of
all
the
lines
which
corresponds
to
1226
line
images
one
or
at
most
two
characters
are
predicted
incorrectly
in
560
line
images
which
corresponds
to
17%
of
all
the
lines
b
displays
cumulative
word
error
rates
following
the
same
manner
output
and
3
the
lexicon
their
methods
select
decoded
words
from
yet
our
method
achieves
close
performance
to
these
works
plus
with
open
and
comprehensive
evaluation
others
exploited
the
attention
based
approaches
to
make
use
of
the
advantages
of
these
methods
on
sequence
learning
in
addition
to
deep
learning
architectures
they
generated
millions
of
synthetic
handwriting
images
and/or
crafted
real
handwriting
images
through
the
web
which
is
another
factor
of
their
success
as
summarized
in
table
10
li
et
al
27
pretrained
transformer
model
on
their
synthetic
dataset
finetuned
over
the
tam
and
achieved
superior
results
with
out
applying
any
post
processing
method
e.g
language
model
or
lexicon
diaz
et
al
7
obtained
the
state
of
the
art
performance
where
they
preferred
simpler
model
with
considerably
less
amount
of
parameters
trained
on
datasets
they
collected
and
supported
the
outputs
with
9-gram
language
model
these
works
suggest
that
the
crucial
part
of
successful
handwriting
recognition
system
is
to
utilize
large
number
of
high
quality
data
either
synthetic
or
real
once
the
data
requirement
is
satisfied
it
is
better
to
employ
the
state
of
the
art
deep
learning
networks
such
as
transformer
vision
transformer
or
other
models
with
atten
tion
mechanism
next
the
final
output
could
be
decided
with
the
help
of
an
n-gram
language
model
to
further
increase
the
success
summary
and
conclusions
we
proposed
cnn-biilstm
model
for
offline
english
handwriting
and
comprehensively
evalu
ated
it
in
regards
to
model
architecture
data
aug
mentation
synthetic
data
generation
and
data
representation
we
have
also
suggested
sim
ple
yet
effective
post
processing
method
utilizing
test
time
augmentation
even
though
the
method
takes
more
time
compared
to
decoding
of
single
image
it
could
be
preferable
in
batch
processes
that
do
not
have
time
constrains
and
it
is
applica
ble
to
any
model
producing
sequence
of
characters
from
images
in
addition
to
the
usual
metrics
for
assess
ing
handwriting
recognition
models
we
analyzed
the
error
distributions
to
gain
insights
regarding
challenges
we
have
shown
that
the
majority
of
the
errors
stem
from
relatively
small
portion
of
the
test
cases
which
can
be
instructive
for
improvements
we
will
share
our
code
openly
upon
publi
cation
to
allow
for
other
researchers
as
well
as
reproducibility
references
1
lancaster-oslo-bergen
corpus
of
modern
english
lob
tagged
horizontal
format
stig
johansson
http://hdl.handle.net/20.500
12024/0167
oxford
text
archive
springer
nature
2021
ibtex
template
f,fﬁ
el
ca///‘(-fg/
true
prediction
with
sir
john
she
enquired
cuttingly
wits
sir
son
she
enquired
cutling
ly
cer
6.0
wer
5.0
dﬂ
hall
as
hog
l(,7
ek
regho
true
prediction
got
hotter
as
the
day
wore
on
and
we
rested
got
hater
as
the
day
we
on
and
he
rastled
cer
7.0
wer
4.0
true
prediction
carrying
it
into
effect
and
subordinate
crying
ie
into
offeree
anda
puler!inte
cer
13.0
wer
6.0
lecarg
a,ocl
nals
ol
9cvicaa
true
prediction
became
great
sighs
of
ecstacy
become
a.cat
sials
ecras
cer
14.0
wer
6.0
v
ke
add
mu
w“&‘m”&
true
prediction
waving
unkissed
from
the
window
and
dai
on
the
pavement
knowing
in
his
morsing
hired
from
the
window
rd
dean
on
the
panime"t
knowing
in
his
cer
18.0
wer
6.0
fig
difficult
samples
from
iam
dataset
test
partition
claiming
samples
for
which
model
predicted
with
character
errors
bigger
than
i.e
cer
are
not
easy
to
read
by
people
as
well
2
bahdanau
d
cho
k
bengio
y
neural
machine
translation
by
jointly
learning
to
align
and
translate
2014
https://doi.org/10.48550/
arxiv.1409.0473
https://arxiv.org/abs/1409.0473
bahl
l
brown
p
de
souza
p
mercer
r
maximum
mutual
information
estimation
of
hidden
markov
model
parameters
for
speech
recognition
in
icassp
86
ieee
interna
tional
conference
on
acoustics
speech
and
signal
processing
vol
11
pp
49-52
1986
https://doi.org/10.1109/icassp.1986.1169179
4
bluche
t
messina
r
gated
convo
lutional
recurrent
neural
networks
for
multilingual
handwriting
recognition
in
2017
14th
iapr
international
conference
on
document
analysis
and
recognition
icdar
vol
01
pp
646-651
2017
https://doi.org/10.1109/icdar.2017.111
5
bunke
h
bengio
s
vinciarelli
a
offline
recognition
of
unconstrained
handwritten
texts
using
hmms
and
statistical
language
models
ieee
trans
actions
on
pattern
analysis
and
machine
17
6
10
11
12
springer
nature
2021
etex
template
ntelligence
26(6
709-720
2004
https://doi.org/10.1109/
tpami.2004.14
cho
k
van
merrienboer
b
gulcehre
c
bahdanau
d
bougares
f
schwenk
h
bengio
y
learning
phrase
repre
sentations
using
rnn
encoder-decoder
for
statistical
machine
translation
2014
https://doi.org/10.48550/
arxiv.1406.1078
https://arxiv.org/abs/1406.1078
https://arxiv.org/abs/2104.07787
dosovitskiy
a
beyer
l
kolesnikov
a
weissenborn
d
zhai
x
unterthiner
t
dehghani
m
minderer
m
heigold
g
gelly
s
uszkoreit
j
houlsby
n
an
image
is
worth
16x16
words
transform
ers
for
image
recognition
at
scale
2020
https://arxiv.org/abs/2010.11929
dutta
k
krishnan
p
mathew
m
jawa
har
c
improving
cnn-rnn
hybrid
networks
for
handwriting
recognition
in
2018
16th
nternational
conference
on
frontiers
in
handwriting
recognition
icfhr
pp
80
85
2018
https://doi.org/10.1109/icfhr
2018.2018.00023
fischer
a
keller
a
frinken
v
bunke
h
lexicon-free
handwritten
word
spotting
using
character
hmms
pattern
recog
nition
letters
33(7
934-942
2012
https://www.sciencedirect.com/science/
article/pii/s0167865511002820
special
issue
on
awards
from
icpr
2010
francis
w.n
kucera
h
brown
cor
us
manual
tech
rep
department
of
linguistics
brown
university
providence
rhode
island
us
1979
http://icame.uib
no/brown/bem.html
graves
sequence
transduction
with
recurrent
neural
networks
2012
https://doi.org/10.48550/
arxiv.1211.3711
https://arxiv.org/abs/1211.3711
diaz
d.h
qin
s
ingle
r
fujii
y
bissacco
a
rethinking
ext
line
recognition
models
2021
https://doi.org/10.48550/
arxiv.2104.07787
https://doi.org/10.48550/arxiv.2010.11929
13
14
16
17
18
19
graves
a
liwicki
m
fernandez
s
bertolami
r
bunke
h
schmidhuber
j
novel
connectionist
system
for
uncon
strained
handwriting
recognition
ieee
transactions
on
pattern
analysis
and
machine
intelligence
31(5
855-868
2009
https://doi.org/10.1109/tpami.2008.137
graves
a
liwicki
m
fernandez
s
bertolami
r
bunke
h
schmidhuber
j
novel
connectionist
system
for
uncon
strained
handwriting
recognition
ieee
transactions
on
pattern
analysis
and
machine
intelligence
31(5
855-868
2009
https://doi.org/10.1109/tpami.2008.137
graves
a
schmidhuber
j
offline
handwriting
recognition
with
multidi
mensional
recurrent
neural
networks
in
koller
d
schuurmans
d
bengio
y
bottou
l
eds
advances
in
neural
information
processing
systems
vol
21
curran
associates
inc
2008
https
//proceedings.neurips.cc/paper/2008/file/
66368270ffd51418ec58bd793f2d9b1b-paper
pdf
grosicki
e
carré
m
brodin
j.m
geoffrois
e
results
of
the
rimes
evaluation
campaign
for
handwritten
mail
processing
in
2009
10th
interna
tional
conference
on
document
analysis
and
recognition
pp
941-945
2009
https://doi.org/10.1109/icdar.2009.224
he
k
zhang
x
ren
s
sun
j
deep
residual
learning
for
image
recognition
pp
770-778
06
2016
https://doi.org/10.1109/cvpr.2016.90
hochreiter
s
schmidhuber
j
long
short-term
memory
neural
computation
9
1735-80
12
1997
https://doi.org/10.1162/nec0.1997.9.8.1735
toffe
s
szegedy
c
batch
normalization
accelerating
deep
network
training
by
reduc
ing
internal
covariate
shift
in
proceedings
of
the
32nd
international
conference
on
inter
national
conference
on
machine
learning
volume
37
p
448-456
icml’15
jmlr.org
2015
springer
nature
2021
ibtex
template
20
jaderberg
m
simonyan
k
zisserman
a
kavukcuoglu
k
spatial
transformer
net
works
in
proceedings
of
the
28th
inter
national
conference
on
neural
information
processing
systems
volume
2
p
2017-2025
nips’15
mit
press
cambridge
ma
usa
2015
21
kang
l
riba
p
rusinol
m
fornés
a
villegas
m
pay
attention
to
what
you
read
non-recurrent
handwritten
text-line
recogni
tion
pattern
recognition
129
108766
2022
22
kang
l
riba
p
villegas
m
fornés
a
rusinol
m
candidate
fusion
integrat
ing
language
modelling
into
sequence-to
sequence
handwritten
word
recognition
archi
tecture
pattern
recognition
112
107790
2021
23
kang
l
toledo
j
riba
p
villegas
m
fornés
a
rusifiol
m
convolve
attend
and
spell
an
attention-based
sequence-to
sequence
model
for
handwritten
word
recog
nition
40th
german
conference
gepr
2018
stuttgart
germany
october
9-12
2018
pro
ceedings
pp
459-472
01
2019
24
kass
d
vats
e
attentionhtr
handwritten
ext
recognition
based
on
attention
encoder
decoder
networks
in
uchida
s
barney
e
eglin
v
eds
document
analysis
systems
pp
507-522
springer
international
publish
ing
cham
2022
25
krizhevsky
a
sutskever
l
hinton
g.e
imagenet
classification
with
deep
convolu
ional
neural
networks
in
proceedings
of
he
25th
international
conference
on
neu
ral
information
processing
systems
volume
p
1097-1105
nips’12
curran
associates
inc
red
hook
ny
usa
2012
26
kizihirmak
f
offline
handwriting
recogni
ion
using
deep
learning
with
emphasis
on
data
augmentation
effects
master’s
thesis
sabanci
university
2022
27
li
m
lv
t
cui
l
lu
y
floren
cio
d
zhang
c
li
z
wei
f
trocr
transformer-based
optical
character
recog
nition
with
pre-trained
models
2021
https://doi.org/10.48550/
arxiv.2109.10282
https://arxiv.org/abs/2109.10282
28
luo
c
zhu
y
jin
l
wang
y
learn
augment
joint
data
augmentation
and
network
optimization
for
text
recognition
2020
ieee/cvf
conference
on
computer
vision
and
pattern
recognition
cvpr
pp
3743-13752
2020
29
marti
u.v
bunke
h
the
iam
database
an
english
sentence
database
for
offline
handwriting
recognition
inter
national
journal
on
document
analysis
and
recognition
5(1
39-46
nov
2002
https://doi.org/10.1007
/5100320200071
https://doi.org/10.1007
/5100320200071
30
merity
s
xiong
c
bradbury
j
socher
r
pointer
sentinel
mixture
models
2016
https://doi.org/10.48550/arxiv.1609.07843
https://arxiv.org/abs/1609.07843
31
michael
j
labahn
r
gruning
t
zollner
j
evaluating
sequence-to
sequence
models
for
handwritten
text
recognition
pp
1286-1293
09
2019
https://doi.org/10.1109/icdar.2019.00208
32
nair
v
hinton
g.e
rectified
linear
units
improve
restricted
boltzmann
machines
in
proceedings
of
the
27th
international
confer
ence
on
international
conference
on
machine
learning
p
807-814
icml’10
omnipress
madison
wi
usa
2010
33
ney
h
essen
u
kneser
r
on
struc
turing
probabilistic
dependences
in
stochas
tic
language
modelling
computer
speech
language
8(1
1-38
1994
34
pechwitz
m
maergner
v
hmm
based
approach
for
handwritten
arabic
word
recognition
using
the
ifn/enit
database
in
seventh
international
conference
on
document
analysis
and
recognition
2003
proceedings
pp
890-894
2003
https://doi.org/10.1109/icdar.2003.1227788
35
ploetz
t
fink
g
markov
models
for
offline
handwriting
recognition
survey
ijdar
12
269-298
12
2009
19
36
37
38
39
40
41
42
springer
nature
2021
etex
template
https://doi.org/10.1007/s10032-009-0098-4
poznanski
a
wolf
l
cnn-n-gram
for
handwriting
word
recognition
in
2016
ieee
conference
on
computer
vision
and
pattern
recognition
cvpr
pp
2305-2314
2016
https://doi.org/10.1109/cvpr.2016.253
are
multidimensional
recurrent
layers
really
necessary
for
handwritten
text
recognition
in
2017
4th
tapr
international
conference
on
document
analysis
and
recognition
icdar
vol
01
pp
67-72
2017
https://doi.org/10.1109/icdar.2017.20
puigcerver
j
scheidl
h
fiel
s
sablatnig
r
word
eam
search
connectionist
temporal
clas
sification
decoding
algorithm
in
2018
16th
nternational
conference
on
frontiers
in
handwriting
recognition
icfhr
pp
253~
258
2018
https://doi.org/10.1109/icfhr
2018.2018.00052
shi
b
bai
x
yao
c
an
end-to-end
trainable
neural
network
for
image-based
sequence
recognition
and
its
application
to
scene
text
recognition
ieee
transac
tions
on
pattern
analysis
and
machine
intelligence
39(11
2298-2304
2017
https://doi.org/10.1109/tpami.2016.2646371
shorten
c
khoshgoftaar
t
survey
on
image
data
augmentation
for
deep
learn
ing
journal
of
big
data
07
2019
https://doi.org/10.1186
/s40537-019-0197-0
simard
p
steinkraus
d
platt
j
best
practices
for
convolutional
neural
networks
applied
to
visual
document
anal
ysis
in
seventh
international
conference
on
document
analysis
and
recognition
2003
proceedings
pp
958-963
2003
https://doi.org/10.1109/icdar.2003.1227801
srivastava
n
hinton
g
krizhevsky
a
sutskever
i
salakhutdinov
r
dropout
simple
way
to
prevent
neural
networks
from
overfitting
journal
of
machine
learn
ing
research
15(56
1929-1958
2014
http
//jmlr.org/papers/v15
/srivastavalda.html
43
44
46
47
bentham
2016
sénchez
jal
dataset
r0
jan
https://doi.org/10.5281
/zenodo.44519
https://doi.org/10.5281
/zenodo.44519
vaswani
a
shazeer
n
parmar
n
uszko
reit
j
jones
l
gomez
a.n
kaiser
l
polosukhin
i
attention
is
all
you
need
in
proceedings
of
the
31st
international
conference
on
neural
information
process
ing
systems
p
6000-6010
nips’17
curran
associates
inc
red
hook
ny
usa
2017
werbos
p
backpropagation
through
time
what
it
does
and
how
to
do
it
proceed
ings
of
the
ieee
78(10
1550-1560
1990
https://doi.org/10.1109/5.58337
wigington
c
stewart
s
davis
b
bar
rett
b
price
b
cohen
s
data
aug
mentation
for
recognition
of
handwritten
words
and
lines
using
cnn-istm
network
in
2017
14th
iapr
international
confer
ence
on
document
analysis
and
recogni
tion
icdar
vol
01
pp
639-645
2017
https://doi.org/10.1109/icdar.2017.110
xiao
s
peng
l
yan
r
wang
s
deep
network
with
pixel-level
rectifica
tion
and
robust
training
for
handwriting
recognition
in
2019
international
con
ference
on
document
analysis
and
recognition
icdar
pp
9-16
2019
https://doi.org/10.1109/icdar.2019.00012
springer
nature
2021
ixtex
template
appendix
incorrect
iam
test
samples
al
wegrs
6'ddode
ar
nlaix}
db
hme
rdvies
and
puns
label
12
o'clock
at
night
at
that
time
pastries
and
buns
issue
crossed-out
hours
another
word
under
the
line
ot
ke
mo
bl
beawiie
yoy
hibockly
<o
label
interest
to
the
mos
doubtless
because
their
habitat
is
issue
crossed-out
word
before
interest
w
0‘17zr;1
7‘5((.’/
w/’;é
34/74/
%}
/%/p/ey/
label
stepping
out
in
their
white
shorts
they
looked
glad
enough
issue
glad
is
not
present
ay
jclm
jan
&tv‘&%
q%o/l%i/
inéan
am/%z;ng
label
|was
i'm
ian
bawley
does
that
mean
anything
issue
labelled
as
i'm
instead
of
i'am
mil
label
|sentence
database
p02-109
issue
completely
wrong
except
the
last
few
letters
ppo2-109
boor
yoo
newspeper
nelus
that
cenunoa[/dfy
label
know
how
you
newspaper
people
value
that
commodity
!
issue
know
is
not
present
_en
ence
au
label
s8
ssseessceqq
fvfyvfvhe
h-»»»9f>
issue
completely
wrong
fig
a1
samples
from
lines
in
the
iam
dataset
test
par
tition
with
wrong
labels
label
denotes
the
ground-truth
text
written
on
the
image
and
issue
indicates
the
error
of
the
label
e.g
word
in
label
is
not
present
in
the
corre
sponding
image
the
corrected
labels
of
the
iam
test
split
will
be
shared
upon
acceptance
